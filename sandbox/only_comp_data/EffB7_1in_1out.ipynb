{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828387f-f568-4554-b7f5-4bb47207e1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from numba import cuda\n",
    "from src.generator import Generator, GetModel\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6706ef9-b49f-4b8b-908e-a4aa69102c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EFFB7': {'IMG_SIZE': 600,\n",
       "  'BATCH_SIZE': 4,\n",
       "  'SEED': 42,\n",
       "  'WEIGHTS': '/app/_data/noisy-student-efficientnet-b7/efficientnetb7_notop.h5'},\n",
       " 'CLASS': {'negative': 0, 'typical': 1, 'indeterminate': 2, 'atypical': 3},\n",
       " 'EFFB4': {'IMG_SIZE': 380,\n",
       "  'BATCH_SIZE': 24,\n",
       "  'SEED': 42,\n",
       "  'WEIGHTS': '/app/_data/efficientnet-b4_noisy-student_notop.h5'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/app/_data/train.csv\")\n",
    "list_wrong = df[(df[\"class\"] != \"negative\") & (df[\"label\"] == \"none 1 0 0 1 1\")][\n",
    "    \"id_image\"\n",
    "].tolist()\n",
    "# df = df.query(\"id_image not in @list_wrong\").reset_index(drop=True)\n",
    "\n",
    "with open(\"/app/_data/base_config.json\", \"r\") as f:\n",
    "    base_config = json.load(f)\n",
    "base_config[\"EFFB4\"][\"IMG_SIZE\"] = 380\n",
    "base_config[\"EFFB4\"][\"BATCH_SIZE\"] = 24\n",
    "base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d0e91-8ddc-4fe4-b2ba-437db31dc3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output1': [0.9121543778801844,\n",
       "  0.5266045892916528,\n",
       "  1.4291516245487366,\n",
       "  3.278467908902692],\n",
       " 'output2': [1.8243087557603688, 0.6887777294475859]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_for_negative = (1 / sum(df['class']=='negative')) * (df.shape[0] / 4.0)\n",
    "weight_for_typical = (1 / sum(df['class']=='typical')) * (df.shape[0] / 4.0)\n",
    "weight_for_indeterminate = (1 / sum(df['class']=='indeterminate')) * (df.shape[0] / 4.0)\n",
    "weight_for_atypical = (1 / sum(df['class']=='atypical')) * (df.shape[0] / 4.0)\n",
    "non_negative = (1 / sum(df['class']!='negative')) * (df.shape[0] / 2.0)\n",
    "negative = (1 / sum(df['class']=='negative')) * (df.shape[0] / 2.0)\n",
    "class_weights={'output1':[weight_for_negative,weight_for_typical,weight_for_indeterminate,weight_for_atypical],'output2':[negative,non_negative]}\n",
    "class_weights\n",
    "loss_weights={'output1':1,'output2':0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead6122-7ad5-4da6-a3e1-ff1e8d2892f9",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ade85a-362d-41d9-9f92-0911de12a51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1077918-8c4e-4be4-afdb-3306a867f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=base_config[\"EFFB7\"][\"SEED\"], shuffle=True)\n",
    "train_ids = []\n",
    "val_ids = []\n",
    "for train_index, valid_index in skf.split(df, df[\"class\"]):\n",
    "    train_ids.append(train_index)\n",
    "    val_ids.append(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eadcd8e-3616-4935-8894-eab1790edf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07f85f-0b5c-429d-92dc-e4a6d003dc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch #0\n",
      "\n",
      "Warning! Model path already exists.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:592: UserWarning: Input dict contained keys ['data'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/211 [=>............................] - ETA: 5:29 - loss: 2.3445 - acc: 0.3919 - auc: 0.5988"
     ]
    }
   ],
   "source": [
    "for n in range(5):\n",
    "    print(\"\\n epoch #\" + str(n) + \"\\n\")\n",
    "    val = df.loc[val_ids[n]].sample(frac=1, random_state=base_config[\"EFFB4\"][\"SEED\"])\n",
    "    train = df.loc[train_ids[n]].sample(frac=1, random_state=base_config[\"EFFB4\"][\"SEED\"])\n",
    "\n",
    "\n",
    "    gen_train = Generator(\n",
    "        df=train,\n",
    "        batch_size=base_config[\"EFFB4\"][\"BATCH_SIZE\"],\n",
    "        seed=base_config[\"EFFB4\"][\"SEED\"],\n",
    "        img_size=base_config[\"EFFB4\"][\"IMG_SIZE\"],\n",
    "        prepared_img_path=\"/app/_data/train_npy_380/\",\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        hard_augment=False,\n",
    "        trans_aug = False,\n",
    "        flip_aug = False,\n",
    "        n_inputs=1,\n",
    "        n_classes=4,\n",
    "        jpg = False,\n",
    "        png=False,\n",
    "        from_dicom=True\n",
    "    )\n",
    "    gen_valid = Generator(\n",
    "        df=val,\n",
    "        batch_size=base_config[\"EFFB4\"][\"BATCH_SIZE\"],\n",
    "        seed=base_config[\"EFFB4\"][\"SEED\"],\n",
    "        img_size=base_config[\"EFFB4\"][\"IMG_SIZE\"],\n",
    "        prepared_img_path=\"/app/_data/train_npy_380/\",\n",
    "        shuffle=False,\n",
    "        augment=False,\n",
    "        hard_augment=False,\n",
    "        flip_aug = False,\n",
    "        n_inputs=1,\n",
    "        n_classes=4,\n",
    "        jpg = False,\n",
    "        png=False,\n",
    "        from_dicom=True\n",
    "    )\n",
    "\n",
    "    get_m = GetModel(\n",
    "    model_name=\"EFFB4\",\n",
    "    n_inputs=1,\n",
    "    lr=0.001,\n",
    "    activation_func=\"softmax\",\n",
    "#     weights=base_config[\"EFFB4\"][\"WEIGHTS\"],\n",
    "    weights='imagenet',\n",
    "    n_classes=4,\n",
    "    top_dropout_rate=None,\n",
    "\n",
    ")\n",
    "    model = get_m.get_model()\n",
    "\n",
    "    callbacks = get_m.make_callback(\n",
    "        model_path=\"/app/_data/models/EffB4_1in_380/\",\n",
    "        model_name=\"EffB4_\" + str(n) + \".h5\",\n",
    "        tensorboard_path=\"/app/.tensorboard/EffB4_1in_380\" + str(n),\n",
    "        patience_ES=20,\n",
    "        patience_RLR=2,\n",
    "        factor_LR=0.7,\n",
    "        metric_for_monitor=\"val_loss\",\n",
    "        metric_mode=\"min\",\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_valid,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=len(train) // base_config[\"EFFB4\"][\"BATCH_SIZE\"],\n",
    "        validation_steps=len(val) // base_config[\"EFFB4\"][\"BATCH_SIZE\"],\n",
    "        verbose=1,\n",
    "        workers=20,\n",
    "        max_queue_size=500,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c0fca-6b7e-46fb-b839-f180382de5f1",
   "metadata": {},
   "source": [
    "# evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccab8a9-3fb6-4f5c-b33b-1a5e3dfe947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(\n",
    "    df=df,\n",
    "    batch_size=base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "    seed=base_config[\"EFFB7\"][\"SEED\"],\n",
    "    img_size=base_config[\"EFFB7\"][\"IMG_SIZE\"],\n",
    "    prepared_img_path=\"/app/_data/train_jpg_600/\",\n",
    "    shuffle=False,\n",
    "    augment=False,\n",
    "    hard_augment=False,\n",
    "    n_inputs=2,\n",
    "    n_classes=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c286f-08a4-4525-a613-b629cc121e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_path = '/app/_data/models/EffB7_init/'\n",
    "for file in os.listdir(mod_path):\n",
    "    if '.h5' in file:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02594349-6e30-4f4d-8060-bc1ad5838b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507/1507 [==============================] - 292s 188ms/step - loss: 0.2460 - acc: 0.8874 - recall: 0.8781 - precision: 0.8973 - f1_score: 0.8871\n",
      "1507/1507 [==============================] - 438s 287ms/step - loss: 0.2491 - acc: 0.7890 - recall: 0.7031 - precision: 0.8661 - f1_score: 0.7756\n",
      "1507/1507 [==============================] - 514s 338ms/step - loss: 0.1905 - acc: 0.9041 - recall: 0.8962 - precision: 0.9099 - f1_score: 0.9048\n",
      "1507/1507 [==============================] - 499s 328ms/step - loss: 0.2422 - acc: 0.7971 - recall: 0.7404 - precision: 0.8551 - f1_score: 0.7619\n"
     ]
    }
   ],
   "source": [
    "mod_path = '/app/_data/models/EffB7_init/'\n",
    "for file in os.listdir(mod_path):\n",
    "    if '.h5' in file:\n",
    "        model = keras.models.load_model(mod_path+file)\n",
    "        model.evaluate(gen)\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64036f55-dc56-4538-be69-eff5325cb649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EffB7_3.h5\n",
      "1507/1507 [==============================] - 320s 206ms/step - loss: 0.4167 - acc: 0.6744 - recall: 0.6176 - precision: 0.7273 - f1_score: 0.5826\n",
      "EffB7_0.h5\n",
      "1507/1507 [==============================] - 497s 326ms/step - loss: 0.3747 - acc: 0.6775 - recall: 0.5979 - precision: 0.7653 - f1_score: 0.5872\n",
      "EffB7_1.h5\n",
      "1507/1507 [==============================] - 514s 338ms/step - loss: 0.3693 - acc: 0.6792 - recall: 0.5906 - precision: 0.7759 - f1_score: 0.5906\n",
      "EffB7_2.h5\n",
      "1507/1507 [==============================] - 501s 329ms/step - loss: 0.3743 - acc: 0.6724 - recall: 0.5907 - precision: 0.7444 - f1_score: 0.5885\n",
      "EffB7_4.h5\n",
      "1507/1507 [==============================] - 532s 350ms/step - loss: 0.3499 - acc: 0.6966 - recall: 0.6339 - precision: 0.7642 - f1_score: 0.6068\n"
     ]
    }
   ],
   "source": [
    "mod_path = '/app/_data/models/EffB7_2/'\n",
    "for file in os.listdir(mod_path):\n",
    "    if '.h5' in file:\n",
    "        print(file)\n",
    "        model = keras.models.load_model(mod_path+file)\n",
    "        model.evaluate(gen)\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1668947c-d55a-4918-adb1-3f82fc26593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EffB7_c_1.h5\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "1507/1507 [==============================] - 241s 155ms/step - loss: 0.2588 - acc: 0.7928 - recall: 0.7636 - precision: 0.8212 - f1_score: 0.7631\n",
      "EffB7_c_2.h5\n",
      "1507/1507 [==============================] - 248s 161ms/step - loss: 0.3700 - acc: 0.6749 - recall: 0.6257 - precision: 0.7250 - f1_score: 0.5922\n",
      "EffB7_c_3.h5\n",
      "1507/1507 [==============================] - 248s 160ms/step - loss: 0.3233 - acc: 0.7162 - recall: 0.6478 - precision: 0.8035 - f1_score: 0.6639\n",
      "EffB7_c_4.h5\n",
      "1507/1507 [==============================] - 226s 146ms/step - loss: 0.4215 - acc: 0.6291 - recall: 0.5717 - precision: 0.6708 - f1_score: 0.5457\n",
      "EffB7_c_0_067.h5\n",
      "1507/1507 [==============================] - 207s 134ms/step - loss: 0.3849 - acc: 0.6632 - recall_1: 0.6289 - precision_1: 0.7001 - f1_score: 0.5733\n",
      "EffB7_c_0.h5\n",
      "1507/1507 [==============================] - 511s 336ms/step - loss: 0.3529 - acc: 0.6899 - recall: 0.6276 - precision: 0.7577 - f1_score: 0.6093\n"
     ]
    }
   ],
   "source": [
    "mod_path = '/app/_data/models/EffB7_comp_data_0_softmax/'\n",
    "for file in os.listdir(mod_path):\n",
    "    if '.h5' in file:\n",
    "        print(file)\n",
    "        model = keras.models.load_model(mod_path+file)\n",
    "        model.evaluate(gen)\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe43dd5e-235c-4c17-b487-7383bcae190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EffB7_3.h5\n",
      "1507/1507 [==============================] - 375s 246ms/step - loss: 0.3712 - acc: 0.6667 - recall: 0.5738 - precision: 0.7562 - f1_score: 0.5888\n",
      "EffB7_0.h5\n",
      "1507/1507 [==============================] - 529s 348ms/step - loss: 0.3892 - acc: 0.6666 - recall: 0.5941 - precision: 0.7284 - f1_score: 0.5757\n",
      "EffB7_1.h5\n",
      "1507/1507 [==============================] - 528s 347ms/step - loss: 0.4477 - acc: 0.6410 - recall: 0.6012 - precision: 0.6746 - f1_score: 0.5579\n",
      "EffB7_2.h5\n",
      " 865/1507 [================>.............] - ETA: 3:41 - loss: 0.3862 - acc: 0.6731 - recall: 0.5841 - precision: 0.7624 - f1_score: 0.5869"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8eaf7ac26627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mod_path = '/app/_data/models/EffB7_3/'\n",
    "for file in os.listdir(mod_path):\n",
    "    if '.h5' in file:\n",
    "        print(file)\n",
    "        model = keras.models.load_model(mod_path+file)\n",
    "        model.evaluate(gen)\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa598371-7f1f-4bdc-a4fb-3e328ae3748d",
   "metadata": {},
   "source": [
    "## evaluation 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c12354-52f8-4669-b622-7e087fcf767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2 = Generator(\n",
    "    df=df,\n",
    "    batch_size=base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "    seed=base_config[\"EFFB7\"][\"SEED\"],\n",
    "    img_size=base_config[\"EFFB7\"][\"IMG_SIZE\"],\n",
    "    prepared_img_path=\"/app/_data/train_jpg_600/\",\n",
    "    shuffle=False,\n",
    "    augment=False,\n",
    "    hard_augment=False,\n",
    "    n_inputs=2,\n",
    "    n_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa541fd0-9618-4065-aa4f-e79a8ab3272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EffB7_2cl_2.h5\n",
      "1507/1507 [==============================] - 223s 145ms/step - loss: 0.3971 - acc: 0.8230 - recall: 0.8230 - precision: 0.8231 - f1_score: 0.8252\n",
      "EffB7_2cl_1.h5\n",
      "1507/1507 [==============================] - 213s 138ms/step - loss: 0.2898 - acc: 0.8769 - recall: 0.8769 - precision: 0.8769 - f1_score: 0.8733\n",
      "EffB7_2cl_0.h5\n",
      "1507/1507 [==============================] - 518s 341ms/step - loss: 0.4272 - acc: 0.8056 - recall: 0.8056 - precision: 0.8056 - f1_score: 0.8027\n",
      "EffB7_2cl_4.h5\n",
      "1507/1507 [==============================] - 215s 140ms/step - loss: 0.3666 - acc: 0.8442 - recall: 0.8442 - precision: 0.8442 - f1_score: 0.8400\n",
      "EffB7_2cl_3.h5\n",
      "1507/1507 [==============================] - 227s 147ms/step - loss: 0.3073 - acc: 0.8668 - recall: 0.8668 - precision: 0.8668 - f1_score: 0.8628\n"
     ]
    }
   ],
   "source": [
    "mod_path = '/app/_data/models/EffB7_2class_1/'\n",
    "for file in os.listdir(mod_path):\n",
    "    if '.h5' in file:\n",
    "        print(file)\n",
    "        model = keras.models.load_model(mod_path+file)\n",
    "        model.evaluate(gen2)\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6211239-a8cb-4bff-8f1d-1bc229360b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
