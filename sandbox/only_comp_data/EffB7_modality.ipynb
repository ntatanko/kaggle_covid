{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a0ce67-5b5d-4957-ba0f-41685f2b51d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from numba import cuda\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.generator import Generator, GetModel\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9a4478-8e3a-440b-83fe-f981fe8c95bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EFFB7': {'IMG_SIZE': 600,\n",
       "  'BATCH_SIZE': 4,\n",
       "  'SEED': 42,\n",
       "  'WEIGHTS': '/app/_data/noisy-student-efficientnet-b7/efficientnetb7_notop.h5'},\n",
       " 'CLASS': {'negative': 0, 'typical': 1, 'indeterminate': 2, 'atypical': 3},\n",
       " 'EFFB4': {'IMG_SIZE': 380,\n",
       "  'BATCH_SIZE': 50,\n",
       "  'SEED': 42,\n",
       "  'WEIGHTS': '/app/_data/efficientnet-b4_noisy-student_notop.h5'},\n",
       " 'EFFB0': {'IMG_SIZE': 224,\n",
       "  'BATCH_SIZE': 120,\n",
       "  'SEED': 42,\n",
       "  'WEIGHTS': 'imagenet'},\n",
       " 'EFFB6': {'IMG_SIZE': 528,\n",
       "  'BATCH_SIZE': 8,\n",
       "  'SEED': 42,\n",
       "  'WEIGHTS': '/app/_data/noisy-student-efficientnet-b6/efficientnetb6_notop.h5'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/app/_data/train.csv\")\n",
    "list_wrong = df[(df[\"class\"] != \"negative\") & (df[\"label\"] == \"none 1 0 0 1 1\")][\n",
    "    \"id_image\"\n",
    "].tolist()\n",
    "df = df.query(\"id_image not in @list_wrong\").reset_index(drop=True)\n",
    "\n",
    "with open(\"/app/_data/base_config.json\", \"r\") as f:\n",
    "    base_config = json.load(f)\n",
    "base_config[\"EFFB7\"][\"SEED\"] = 42\n",
    "base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8049f45c-01a2-4328-acfb-eeffbd11d2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       DX\n",
       "1       CR\n",
       "2       DX\n",
       "3       CR\n",
       "4       DX\n",
       "        ..\n",
       "6329    CR\n",
       "6330    DX\n",
       "6331    DX\n",
       "6332    DX\n",
       "6333    CR\n",
       "Name: modality, Length: 6334, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4faf29b2-ab69-477d-9429-d3f631d796db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output1': [0.9121543778801844,\n",
       "  0.5266045892916528,\n",
       "  1.4291516245487366,\n",
       "  3.278467908902692],\n",
       " 'output2': [1.8243087557603688, 0.6887777294475859]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_for_negative = (1 / sum(df[\"class\"] == \"negative\")) * (df.shape[0] / 4.0)\n",
    "weight_for_typical = (1 / sum(df[\"class\"] == \"typical\")) * (df.shape[0] / 4.0)\n",
    "weight_for_indeterminate = (1 / sum(df[\"class\"] == \"indeterminate\")) * (\n",
    "    df.shape[0] / 4.0\n",
    ")\n",
    "weight_for_atypical = (1 / sum(df[\"class\"] == \"atypical\")) * (df.shape[0] / 4.0)\n",
    "non_negative = (1 / sum(df[\"class\"] != \"negative\")) * (df.shape[0] / 2.0)\n",
    "negative = (1 / sum(df[\"class\"] == \"negative\")) * (df.shape[0] / 2.0)\n",
    "class_weights = {\n",
    "    \"output1\": [\n",
    "        weight_for_negative,\n",
    "        weight_for_typical,\n",
    "        weight_for_indeterminate,\n",
    "        weight_for_atypical,\n",
    "    ],\n",
    "    \"output2\": [negative, non_negative],\n",
    "}\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e40a11-6651-47ae-9bce-b490b629c083",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f165a07-baf1-4a4a-b379-eec3b4e16653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dx = df.query('modality==\"DX\"').reset_index(drop=True)\n",
    "df_cr = df.query('modality==\"CR\"').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0a37d-4614-443a-8894-78ffe752347a",
   "metadata": {},
   "source": [
    "## DX modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89416787-ace9-46d8-b5ad-25f9928f41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(\n",
    "    n_splits=5, random_state=base_config[\"EFFB7\"][\"SEED\"], shuffle=True\n",
    ")\n",
    "train_ids = []\n",
    "val_ids = []\n",
    "for train_index, valid_index in skf.split(df_dx, df_dx[\"class\"]):\n",
    "    train_ids.append(train_index)\n",
    "    val_ids.append(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc509b4-b21d-41de-9f6e-87a7fd558719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a91731-9d1a-41b4-9c44-56c63f927dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch #2\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Warning! Model path already exists.\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:592: UserWarning: Input dict contained keys ['data'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 374s 470ms/step - loss: 1.3263 - acc: 0.4894 - val_loss: nan - val_acc: 0.2941\n",
      "\n",
      "Epoch 00009: val_acc improved from -inf to 0.29412, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_2.h5\n",
      "Epoch 10/50\n",
      "612/612 [==============================] - 277s 452ms/step - loss: 1.3858 - acc: 0.4560 - val_loss: 21.5106 - val_acc: 0.4608\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.29412 to 0.46078, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_2.h5\n",
      "Epoch 11/50\n",
      "612/612 [==============================] - 301s 492ms/step - loss: 1.3011 - acc: 0.5258 - val_loss: 1.9469 - val_acc: 0.5817\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.46078 to 0.58170, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_2.h5\n",
      "Epoch 12/50\n",
      "612/612 [==============================] - 303s 494ms/step - loss: 1.2653 - acc: 0.5348 - val_loss: nan - val_acc: 0.5196\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.58170\n",
      "Epoch 13/50\n",
      "612/612 [==============================] - 307s 501ms/step - loss: 1.2623 - acc: 0.5207 - val_loss: nan - val_acc: 0.5310\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.58170\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00043740003020502626.\n",
      "Epoch 14/50\n",
      "612/612 [==============================] - 293s 479ms/step - loss: 1.2232 - acc: 0.5370 - val_loss: 3.3345 - val_acc: 0.5621\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58170\n",
      "Epoch 15/50\n",
      "612/612 [==============================] - 303s 495ms/step - loss: 1.2544 - acc: 0.5384 - val_loss: 1.5537 - val_acc: 0.4592\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.58170\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0003936600376619026.\n",
      "Epoch 16/50\n",
      "612/612 [==============================] - 285s 466ms/step - loss: 1.2910 - acc: 0.5388 - val_loss: 4.7014 - val_acc: 0.4771\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.58170\n",
      "Epoch 17/50\n",
      "612/612 [==============================] - 287s 469ms/step - loss: 1.2364 - acc: 0.5371 - val_loss: 1.2280 - val_acc: 0.5441\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.58170\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0003542940365150571.\n",
      "Epoch 18/50\n",
      "612/612 [==============================] - 298s 487ms/step - loss: 1.1616 - acc: 0.5559 - val_loss: 3.7463 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.58170\n",
      "Epoch 19/50\n",
      "612/612 [==============================] - 283s 463ms/step - loss: 1.1925 - acc: 0.5595 - val_loss: nan - val_acc: 0.4804\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.58170\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0003188646223861724.\n",
      "Epoch 20/50\n",
      "612/612 [==============================] - 294s 480ms/step - loss: 1.1762 - acc: 0.5650 - val_loss: nan - val_acc: 0.6013\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.58170 to 0.60131, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_2.h5\n",
      "Epoch 21/50\n",
      "612/612 [==============================] - 282s 459ms/step - loss: 1.2158 - acc: 0.5374 - val_loss: nan - val_acc: 0.5458\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.60131\n",
      "Epoch 22/50\n",
      "612/612 [==============================] - 283s 462ms/step - loss: 1.1790 - acc: 0.5668 - val_loss: nan - val_acc: 0.5425\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.60131\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00028697816014755517.\n",
      "Epoch 23/50\n",
      "612/612 [==============================] - 293s 479ms/step - loss: 1.1868 - acc: 0.5595 - val_loss: nan - val_acc: 0.5588\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.60131\n",
      "Epoch 24/50\n",
      "612/612 [==============================] - 295s 481ms/step - loss: 1.1754 - acc: 0.5573 - val_loss: nan - val_acc: 0.4624\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.60131\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00025828033103607594.\n",
      "Epoch 25/50\n",
      "612/612 [==============================] - 296s 484ms/step - loss: 1.1392 - acc: 0.5785 - val_loss: nan - val_acc: 0.4967\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.60131\n",
      "Epoch 26/50\n",
      "612/612 [==============================] - 313s 511ms/step - loss: 1.1825 - acc: 0.5631 - val_loss: 1.7490 - val_acc: 0.6193\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.60131 to 0.61928, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_2.h5\n",
      "Epoch 27/50\n",
      "612/612 [==============================] - 212s 345ms/step - loss: 1.1595 - acc: 0.5701 - val_loss: nan - val_acc: 0.5343\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.61928\n",
      "Epoch 28/50\n",
      "612/612 [==============================] - 173s 283ms/step - loss: 1.1426 - acc: 0.5644 - val_loss: nan - val_acc: 0.5343\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.61928\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00023245230840984732.\n",
      "Epoch 29/50\n",
      "612/612 [==============================] - 160s 261ms/step - loss: 1.1365 - acc: 0.5672 - val_loss: nan - val_acc: 0.5261\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.61928\n",
      "Epoch 30/50\n",
      "612/612 [==============================] - 160s 261ms/step - loss: 1.1269 - acc: 0.5658 - val_loss: nan - val_acc: 0.5114\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.61928\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002092070775688626.\n",
      "Epoch 31/50\n",
      "612/612 [==============================] - 157s 256ms/step - loss: 1.1142 - acc: 0.5867 - val_loss: nan - val_acc: 0.5556\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.61928\n",
      "Epoch 32/50\n",
      "612/612 [==============================] - 153s 250ms/step - loss: 1.1018 - acc: 0.5889 - val_loss: nan - val_acc: 0.5196\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.61928\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0001882863711216487.\n",
      "Epoch 33/50\n",
      "612/612 [==============================] - 157s 256ms/step - loss: 1.1365 - acc: 0.5741 - val_loss: nan - val_acc: 0.5376\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.61928\n",
      "Epoch 34/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 1.0978 - acc: 0.5778 - val_loss: nan - val_acc: 0.5310\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.61928\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0001694577353191562.\n",
      "Epoch 35/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 1.0539 - acc: 0.5970 - val_loss: nan - val_acc: 0.5441\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.61928\n",
      "Epoch 36/50\n",
      "612/612 [==============================] - 156s 254ms/step - loss: 1.0409 - acc: 0.6075 - val_loss: nan - val_acc: 0.5670\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.61928\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00015251196309691296.\n",
      "Epoch 37/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 1.0748 - acc: 0.5877 - val_loss: nan - val_acc: 0.5229\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.61928\n",
      "Epoch 38/50\n",
      "612/612 [==============================] - 157s 256ms/step - loss: 1.0303 - acc: 0.6237 - val_loss: nan - val_acc: 0.5441\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.61928\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00013726076285820455.\n",
      "Epoch 00038: early stopping\n",
      "\n",
      " epoch #3\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Warning! Model path already exists.\n",
      "Epoch 1/50\n",
      "612/612 [==============================] - 207s 276ms/step - loss: 1.7094 - acc: 0.3495 - val_loss: 2.8747 - val_acc: 0.4118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.41176, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_3.h5\n",
      "Epoch 2/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 1.5090 - acc: 0.3819 - val_loss: 4.4792 - val_acc: 0.2908\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.41176\n",
      "Epoch 3/50\n",
      "612/612 [==============================] - 155s 252ms/step - loss: 1.6582 - acc: 0.3703 - val_loss: 10.7027 - val_acc: 0.3497\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.41176\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005400000256486237.\n",
      "Epoch 4/50\n",
      "612/612 [==============================] - 155s 253ms/step - loss: 1.4692 - acc: 0.3878 - val_loss: 1.4005 - val_acc: 0.4706\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.41176 to 0.47059, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_3.h5\n",
      "Epoch 5/50\n",
      "612/612 [==============================] - 152s 247ms/step - loss: 1.4625 - acc: 0.4135 - val_loss: 8.5633 - val_acc: 0.4788\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.47059 to 0.47876, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_3.h5\n",
      "Epoch 6/50\n",
      "612/612 [==============================] - 152s 248ms/step - loss: 1.4933 - acc: 0.3955 - val_loss: 3.0915 - val_acc: 0.2990\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.47876\n",
      "Epoch 7/50\n",
      "612/612 [==============================] - 153s 250ms/step - loss: 1.4709 - acc: 0.4140 - val_loss: 1.3476 - val_acc: 0.4706\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.47876\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0004860000335611403.\n",
      "Epoch 8/50\n",
      "612/612 [==============================] - 155s 253ms/step - loss: 1.4512 - acc: 0.4253 - val_loss: 2.2025 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.47876\n",
      "Epoch 9/50\n",
      "612/612 [==============================] - 155s 252ms/step - loss: 1.3845 - acc: 0.4141 - val_loss: nan - val_acc: 0.4510\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.47876\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00043740003020502626.\n",
      "Epoch 10/50\n",
      "612/612 [==============================] - 155s 252ms/step - loss: 1.3932 - acc: 0.4152 - val_loss: 9.8826 - val_acc: 0.4444\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.47876\n",
      "Epoch 11/50\n",
      "612/612 [==============================] - 154s 250ms/step - loss: 1.3924 - acc: 0.4017 - val_loss: 2.0258 - val_acc: 0.4575\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.47876\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003936600376619026.\n",
      "Epoch 12/50\n",
      "612/612 [==============================] - 153s 250ms/step - loss: 1.3452 - acc: 0.4655 - val_loss: nan - val_acc: 0.4477\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.47876\n",
      "Epoch 13/50\n",
      "612/612 [==============================] - 154s 251ms/step - loss: 1.3308 - acc: 0.4337 - val_loss: nan - val_acc: 0.4526\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.47876\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003542940365150571.\n",
      "Epoch 14/50\n",
      "612/612 [==============================] - 154s 251ms/step - loss: 1.3620 - acc: 0.4348 - val_loss: 2.3473 - val_acc: 0.4592\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.47876\n",
      "Epoch 15/50\n",
      "612/612 [==============================] - 155s 253ms/step - loss: 1.4015 - acc: 0.4296 - val_loss: 1.2284 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.47876\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0003188646223861724.\n",
      "Epoch 16/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 1.3462 - acc: 0.4169 - val_loss: 1.2471 - val_acc: 0.4706\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.47876\n",
      "Epoch 17/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 1.3459 - acc: 0.4086 - val_loss: 1.7624 - val_acc: 0.4739\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.47876\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00028697816014755517.\n",
      "Epoch 00017: early stopping\n",
      "\n",
      " epoch #4\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Warning! Model path already exists.\n",
      "Epoch 1/50\n",
      "612/612 [==============================] - 207s 275ms/step - loss: 1.8112 - acc: 0.3540 - val_loss: 78.0928 - val_acc: 0.2810\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28105, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_4.h5\n",
      "Epoch 2/50\n",
      "612/612 [==============================] - 152s 248ms/step - loss: 1.7249 - acc: 0.3738 - val_loss: 2.7478 - val_acc: 0.4706\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28105 to 0.47059, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_4.h5\n",
      "Epoch 3/50\n",
      "612/612 [==============================] - 154s 250ms/step - loss: 1.4309 - acc: 0.4139 - val_loss: 2.3316 - val_acc: 0.4412\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.47059\n",
      "Epoch 4/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 1.4929 - acc: 0.3916 - val_loss: 8.8853 - val_acc: 0.4314\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.47059\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005400000256486237.\n",
      "Epoch 5/50\n",
      "612/612 [==============================] - 152s 248ms/step - loss: 1.5178 - acc: 0.4187 - val_loss: 4.0957 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.47059\n",
      "Epoch 6/50\n",
      "612/612 [==============================] - 154s 251ms/step - loss: 1.4596 - acc: 0.3873 - val_loss: 18.3802 - val_acc: 0.4592\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.47059\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0004860000335611403.\n",
      "Epoch 7/50\n",
      "612/612 [==============================] - 154s 251ms/step - loss: 1.4542 - acc: 0.4244 - val_loss: 23.0574 - val_acc: 0.1879\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.47059\n",
      "Epoch 8/50\n",
      "612/612 [==============================] - 153s 250ms/step - loss: 1.3850 - acc: 0.4136 - val_loss: 5.6846 - val_acc: 0.4314\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.47059\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00043740003020502626.\n",
      "Epoch 9/50\n",
      "612/612 [==============================] - 155s 252ms/step - loss: 1.4370 - acc: 0.4151 - val_loss: 1.5474 - val_acc: 0.4085\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.47059\n",
      "Epoch 10/50\n",
      "612/612 [==============================] - 153s 250ms/step - loss: 1.4077 - acc: 0.3925 - val_loss: 1.4755 - val_acc: 0.4673\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.47059\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0003936600376619026.\n",
      "Epoch 11/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 1.2480 - acc: 0.4363 - val_loss: 1.3344 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.47059\n",
      "Epoch 12/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 1.1855 - acc: 0.5079 - val_loss: 1.3300 - val_acc: 0.4755\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.47059 to 0.47549, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_4.h5\n",
      "Epoch 13/50\n",
      "612/612 [==============================] - 155s 253ms/step - loss: 1.1515 - acc: 0.5418 - val_loss: 1.0987 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.47549 to 0.58497, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_4.h5\n",
      "Epoch 14/50\n",
      "612/612 [==============================] - 155s 253ms/step - loss: 1.1036 - acc: 0.5687 - val_loss: nan - val_acc: 0.4428\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58497\n",
      "Epoch 15/50\n",
      "612/612 [==============================] - 155s 252ms/step - loss: 1.1191 - acc: 0.5382 - val_loss: 3.2782 - val_acc: 0.4837\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.58497\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0003542940365150571.\n",
      "Epoch 16/50\n",
      "612/612 [==============================] - 155s 254ms/step - loss: 1.0835 - acc: 0.5643 - val_loss: 1.5645 - val_acc: 0.5343\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.58497\n",
      "Epoch 17/50\n",
      "612/612 [==============================] - 157s 254ms/step - loss: 1.1060 - acc: 0.5624 - val_loss: nan - val_acc: 0.4363\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.58497\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0003188646223861724.\n",
      "Epoch 18/50\n",
      "612/612 [==============================] - 156s 254ms/step - loss: 1.0421 - acc: 0.5962 - val_loss: 1.3573 - val_acc: 0.5621\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.58497\n",
      "Epoch 19/50\n",
      "612/612 [==============================] - 157s 256ms/step - loss: 1.0445 - acc: 0.5847 - val_loss: nan - val_acc: 0.5049\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.58497\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00028697816014755517.\n",
      "Epoch 20/50\n",
      "612/612 [==============================] - 155s 254ms/step - loss: 1.0120 - acc: 0.5981 - val_loss: nan - val_acc: 0.5621\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.58497\n",
      "Epoch 21/50\n",
      "612/612 [==============================] - 155s 254ms/step - loss: 1.0328 - acc: 0.5917 - val_loss: 1.0585 - val_acc: 0.6209\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.58497 to 0.62092, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_4.h5\n",
      "Epoch 22/50\n",
      "612/612 [==============================] - 156s 254ms/step - loss: 1.0293 - acc: 0.6018 - val_loss: 1.0205 - val_acc: 0.6209\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.62092\n",
      "Epoch 23/50\n",
      "612/612 [==============================] - 157s 255ms/step - loss: 0.9825 - acc: 0.6245 - val_loss: 1.0034 - val_acc: 0.6258\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.62092 to 0.62582, saving model to /app/_data/models/DX_CR/EffB7_HA_1/EffB7_4.h5\n",
      "Epoch 24/50\n",
      "612/612 [==============================] - 156s 254ms/step - loss: 0.9689 - acc: 0.6336 - val_loss: 1.0841 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.62582\n",
      "Epoch 25/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 0.9829 - acc: 0.6303 - val_loss: 1.3914 - val_acc: 0.5931\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.62582\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00025828033103607594.\n",
      "Epoch 26/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 0.9332 - acc: 0.6511 - val_loss: 1.0973 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.62582\n",
      "Epoch 27/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 0.9203 - acc: 0.6594 - val_loss: 1.3643 - val_acc: 0.5605\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.62582\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00023245230840984732.\n",
      "Epoch 28/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 0.9138 - acc: 0.6526 - val_loss: 1.1204 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.62582\n",
      "Epoch 29/50\n",
      "612/612 [==============================] - 156s 254ms/step - loss: 0.8548 - acc: 0.6712 - val_loss: nan - val_acc: 0.5670\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.62582\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002092070775688626.\n",
      "Epoch 30/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 0.8640 - acc: 0.6652 - val_loss: 1.1515 - val_acc: 0.6062\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.62582\n",
      "Epoch 31/50\n",
      "612/612 [==============================] - 157s 257ms/step - loss: 0.8527 - acc: 0.6803 - val_loss: 1.1964 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.62582\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001882863711216487.\n",
      "Epoch 32/50\n",
      "612/612 [==============================] - 156s 254ms/step - loss: 0.8516 - acc: 0.6834 - val_loss: nan - val_acc: 0.5817\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.62582\n",
      "Epoch 33/50\n",
      "612/612 [==============================] - 156s 255ms/step - loss: 0.8259 - acc: 0.6873 - val_loss: 1.3758 - val_acc: 0.5948\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.62582\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0001694577353191562.\n",
      "Epoch 34/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 0.7903 - acc: 0.7035 - val_loss: 1.2685 - val_acc: 0.5899\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.62582\n",
      "Epoch 35/50\n",
      "612/612 [==============================] - 154s 252ms/step - loss: 0.8159 - acc: 0.6833 - val_loss: 1.1057 - val_acc: 0.6127\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.62582\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00015251196309691296.\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "for n in range(2,5):\n",
    "    print(\"\\n epoch #\" + str(n) + \"\\n\")\n",
    "    val = df_dx.loc[val_ids[n]].sample(frac=1, random_state=base_config[\"EFFB7\"][\"SEED\"])\n",
    "    train = df_dx.loc[train_ids[n]].sample(\n",
    "        frac=1, random_state=base_config[\"EFFB7\"][\"SEED\"]\n",
    "    )\n",
    "\n",
    "    gen_train = Generator(\n",
    "        df=train,\n",
    "        batch_size=base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "        seed=base_config[\"EFFB7\"][\"SEED\"],\n",
    "        img_size=base_config[\"EFFB7\"][\"IMG_SIZE\"],\n",
    "        prepared_img_path=\"/app/_data/train_npy_600/\",\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        hard_augment=True,\n",
    "        trans_aug=False,\n",
    "        flip_aug=False,\n",
    "        n_inputs=1,\n",
    "        n_classes=4,\n",
    "        jpg=False,\n",
    "        png=False,\n",
    "        from_dicom=True,\n",
    "    )\n",
    "    gen_valid = Generator(\n",
    "        df=val,\n",
    "        batch_size=base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "        seed=base_config[\"EFFB7\"][\"SEED\"],\n",
    "        img_size=base_config[\"EFFB7\"][\"IMG_SIZE\"],\n",
    "        prepared_img_path=\"/app/_data/train_npy_600/\",\n",
    "        shuffle=False,\n",
    "        augment=False,\n",
    "        hard_augment=False,\n",
    "        flip_aug=False,\n",
    "        n_inputs=1,\n",
    "        n_classes=4,\n",
    "        jpg=False,\n",
    "        png=False,\n",
    "        from_dicom=True,\n",
    "    )\n",
    "\n",
    "    get_m = GetModel(\n",
    "        model_name=\"EFFB7\",\n",
    "        n_inputs=1,\n",
    "        lr=0.0006,\n",
    "        activation_func=\"softmax\",\n",
    "        weights=base_config[\"EFFB7\"][\"WEIGHTS\"],\n",
    "        n_classes=4,\n",
    "        top_dropout_rate=None,\n",
    "        auc=None\n",
    "    )\n",
    "    model = get_m.get_model()\n",
    "\n",
    "    callbacks = get_m.make_callback(\n",
    "        model_path=\"/app/_data/models/DX_CR/EffB7_HA_1/\",\n",
    "        model_name=\"EffB7_\" + str(n) + \".h5\",\n",
    "        tensorboard_path=\"/app/.tensorboard/EffB7_HA_1\" + str(n),\n",
    "        patience_ES=12,\n",
    "        patience_RLR=2,\n",
    "        factor_LR=0.9,\n",
    "        metric_for_monitor=\"val_acc\",\n",
    "        metric_mode=\"max\",\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_valid,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=len(train) // base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "        validation_steps=len(val) // base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "        verbose=1,\n",
    "        workers=20,\n",
    "        max_queue_size=500,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd230ca9-0fb3-4a0f-8fc4-b8ae85147bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
