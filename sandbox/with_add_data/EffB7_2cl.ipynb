{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86638da4-4c86-498d-9d7c-c1f551464278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.generator import Generator, GetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a650d8e1-74f9-42f3-b494-1d5eaef19619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/app/_data/train.csv\")\n",
    "list_wrong = df[(df[\"class\"] != \"negative\") & (df[\"label\"] == \"none 1 0 0 1 1\")][\n",
    "    \"id_image\"\n",
    "].tolist()\n",
    "df = df.query(\"id_image not in @list_wrong\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608d29bf-6300-4afb-a3c7-02b384a102f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/app/_data/base_config.json\", \"r\") as f:\n",
    "    base_config = json.load(f)\n",
    "base_config[\"EFFB7\"][\"BATCH_SIZE\"] = 4\n",
    "base_config[\"EFFB7\"][\"SEED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b92929d-0a03-46e1-9c10-0d4fb041a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/app/_data/additional_dataset/labels_full.csv\")\n",
    "labels = labels.query(\"Target==0\").reset_index(drop=True)\n",
    "labels[\"image\"] = labels[\"patientId\"] + \".dcm\"\n",
    "labels[\"class\"] = \"negative\"\n",
    "labels = labels[[\"image\", \"class\", \"modality\", \"PatientSex\", \"BodyPartExamined\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9c19d-d3d1-436e-8ac7-f79e2506abe9",
   "metadata": {},
   "source": [
    "# val only from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6245e5a4-6d23-4f15-a914-b8d1d2c48d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1488, shuffle=True)\n",
    "train_ids = []\n",
    "val_ids = []\n",
    "for train_index, valid_index in skf.split(df, df[\"class\"]):\n",
    "    train_ids.append(train_index)\n",
    "    val_ids.append(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b2c75-0577-47b3-9b94-cb75a36d1f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/matplotlib/text.py:1215: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "Warning! Model path already exists.\n",
      "Epoch 1/50\n",
      "652/652 [==============================] - 819s 1s/step - loss: 0.6619 - acc: 0.6505 - recall: 0.6505 - precision: 0.6505 - f1_score: 0.6489 - val_loss: 1.0364 - val_acc: 0.4475 - val_recall: 0.4475 - val_precision: 0.4475 - val_f1_score: 0.4112\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_0.h5\n",
      "Epoch 2/50\n",
      "652/652 [==============================] - 799s 1s/step - loss: 0.5349 - acc: 0.7543 - recall: 0.7543 - precision: 0.7543 - f1_score: 0.7533 - val_loss: 0.6504 - val_acc: 0.6825 - val_recall: 0.6825 - val_precision: 0.6825 - val_f1_score: 0.6921\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.44750 to 0.68250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_0.h5\n",
      "Epoch 3/50\n",
      "652/652 [==============================] - 778s 1s/step - loss: 0.5010 - acc: 0.7652 - recall: 0.7652 - precision: 0.7652 - f1_score: 0.7640 - val_loss: 0.6257 - val_acc: 0.7150 - val_recall: 0.7150 - val_precision: 0.7150 - val_f1_score: 0.7097\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68250 to 0.71500, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_0.h5\n",
      "Epoch 4/50\n",
      "652/652 [==============================] - 754s 1s/step - loss: 0.4838 - acc: 0.7679 - recall: 0.7679 - precision: 0.7679 - f1_score: 0.7664 - val_loss: 0.6338 - val_acc: 0.7025 - val_recall: 0.7025 - val_precision: 0.7025 - val_f1_score: 0.7118\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.71500\n",
      "Epoch 5/50\n",
      "652/652 [==============================] - 720s 1s/step - loss: 0.4664 - acc: 0.7817 - recall: 0.7817 - precision: 0.7817 - f1_score: 0.7814 - val_loss: 0.6254 - val_acc: 0.6625 - val_recall: 0.6625 - val_precision: 0.6625 - val_f1_score: 0.6723\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.71500\n",
      "Epoch 6/50\n",
      "652/652 [==============================] - 754s 1s/step - loss: 0.4864 - acc: 0.7719 - recall: 0.7719 - precision: 0.7719 - f1_score: 0.7709 - val_loss: 0.5895 - val_acc: 0.7300 - val_recall: 0.7300 - val_precision: 0.7300 - val_f1_score: 0.7052\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.71500 to 0.73000, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_0.h5\n",
      "Epoch 7/50\n",
      "652/652 [==============================] - 748s 1s/step - loss: 0.4573 - acc: 0.7921 - recall: 0.7921 - precision: 0.7921 - f1_score: 0.7916 - val_loss: 0.6506 - val_acc: 0.7050 - val_recall: 0.7050 - val_precision: 0.7050 - val_f1_score: 0.7003\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.73000\n",
      "Epoch 8/50\n",
      "652/652 [==============================] - 756s 1s/step - loss: 0.4492 - acc: 0.7970 - recall: 0.7970 - precision: 0.7970 - f1_score: 0.7968 - val_loss: 0.7178 - val_acc: 0.6725 - val_recall: 0.6725 - val_precision: 0.6725 - val_f1_score: 0.6676\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.73000\n",
      "Epoch 9/50\n",
      "652/652 [==============================] - 775s 1s/step - loss: 0.4244 - acc: 0.8087 - recall: 0.8087 - precision: 0.8087 - f1_score: 0.8084 - val_loss: 0.6547 - val_acc: 0.6700 - val_recall: 0.6700 - val_precision: 0.6700 - val_f1_score: 0.6806\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.73000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000559999980032444.\n",
      "Epoch 10/50\n",
      "652/652 [==============================] - 755s 1s/step - loss: 0.4156 - acc: 0.8048 - recall: 0.8048 - precision: 0.8048 - f1_score: 0.8043 - val_loss: 0.5088 - val_acc: 0.7575 - val_recall: 0.7575 - val_precision: 0.7575 - val_f1_score: 0.7607\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.73000 to 0.75750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_0.h5\n",
      "Epoch 11/50\n",
      "652/652 [==============================] - 743s 1s/step - loss: 0.4151 - acc: 0.8057 - recall: 0.8057 - precision: 0.8057 - f1_score: 0.8055 - val_loss: 0.5694 - val_acc: 0.7425 - val_recall: 0.7425 - val_precision: 0.7425 - val_f1_score: 0.7387\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.75750\n",
      "Epoch 12/50\n",
      "652/652 [==============================] - 766s 1s/step - loss: 0.3970 - acc: 0.8264 - recall: 0.8264 - precision: 0.8264 - f1_score: 0.8261 - val_loss: 0.5527 - val_acc: 0.7425 - val_recall: 0.7425 - val_precision: 0.7425 - val_f1_score: 0.7479\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75750\n",
      "Epoch 13/50\n",
      "652/652 [==============================] - 759s 1s/step - loss: 0.4027 - acc: 0.8237 - recall: 0.8237 - precision: 0.8237 - f1_score: 0.8236 - val_loss: 0.4648 - val_acc: 0.7825 - val_recall: 0.7825 - val_precision: 0.7825 - val_f1_score: 0.7803\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.75750 to 0.78250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_0.h5\n",
      "Epoch 14/50\n",
      "652/652 [==============================] - 751s 1s/step - loss: 0.3873 - acc: 0.8280 - recall: 0.8280 - precision: 0.8280 - f1_score: 0.8284 - val_loss: 0.4908 - val_acc: 0.7750 - val_recall: 0.7750 - val_precision: 0.7750 - val_f1_score: 0.7785\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.78250\n",
      "Epoch 15/50\n",
      "652/652 [==============================] - 766s 1s/step - loss: 0.3887 - acc: 0.8220 - recall: 0.8220 - precision: 0.8220 - f1_score: 0.8217 - val_loss: 0.4776 - val_acc: 0.7800 - val_recall: 0.7800 - val_precision: 0.7800 - val_f1_score: 0.7786\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78250\n",
      "Epoch 16/50\n",
      "652/652 [==============================] - 770s 1s/step - loss: 0.3536 - acc: 0.8426 - recall: 0.8426 - precision: 0.8426 - f1_score: 0.8424 - val_loss: 0.4835 - val_acc: 0.7575 - val_recall: 0.7575 - val_precision: 0.7575 - val_f1_score: 0.7545\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78250\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00044799996539950375.\n",
      "Epoch 17/50\n",
      "652/652 [==============================] - 780s 1s/step - loss: 0.3247 - acc: 0.8603 - recall: 0.8603 - precision: 0.8603 - f1_score: 0.8601 - val_loss: 0.5368 - val_acc: 0.7600 - val_recall: 0.7600 - val_precision: 0.7600 - val_f1_score: 0.7535\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78250\n",
      "Epoch 18/50\n",
      "652/652 [==============================] - 764s 1s/step - loss: 0.3395 - acc: 0.8587 - recall: 0.8587 - precision: 0.8587 - f1_score: 0.8585 - val_loss: 0.6458 - val_acc: 0.7225 - val_recall: 0.7225 - val_precision: 0.7225 - val_f1_score: 0.6731\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.78250\n",
      "Epoch 19/50\n",
      "652/652 [==============================] - 787s 1s/step - loss: 0.3579 - acc: 0.8345 - recall: 0.8345 - precision: 0.8345 - f1_score: 0.8347 - val_loss: 0.5468 - val_acc: 0.7525 - val_recall: 0.7525 - val_precision: 0.7525 - val_f1_score: 0.7600\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.78250\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00035839998163282876.\n",
      "Epoch 20/50\n",
      "652/652 [==============================] - 800s 1s/step - loss: 0.3152 - acc: 0.8593 - recall: 0.8593 - precision: 0.8593 - f1_score: 0.8594 - val_loss: 0.4897 - val_acc: 0.7700 - val_recall: 0.7700 - val_precision: 0.7700 - val_f1_score: 0.7757\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.78250\n",
      "Epoch 21/50\n",
      "652/652 [==============================] - 786s 1s/step - loss: 0.2986 - acc: 0.8691 - recall: 0.8691 - precision: 0.8691 - f1_score: 0.8691 - val_loss: 0.4972 - val_acc: 0.7800 - val_recall: 0.7800 - val_precision: 0.7800 - val_f1_score: 0.7848\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.78250\n",
      "Epoch 22/50\n",
      "652/652 [==============================] - 748s 1s/step - loss: 0.3471 - acc: 0.8526 - recall: 0.8526 - precision: 0.8526 - f1_score: 0.8525 - val_loss: 0.5028 - val_acc: 0.7675 - val_recall: 0.7675 - val_precision: 0.7675 - val_f1_score: 0.7663\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.78250\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002867199946194887.\n",
      "Epoch 23/50\n",
      "652/652 [==============================] - 785s 1s/step - loss: 0.3022 - acc: 0.8672 - recall: 0.8672 - precision: 0.8672 - f1_score: 0.8672 - val_loss: 0.4954 - val_acc: 0.7825 - val_recall: 0.7825 - val_precision: 0.7825 - val_f1_score: 0.7873\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.78250\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Warning! Model path already exists.\n",
      "Epoch 1/50\n",
      "652/652 [==============================] - 387s 497ms/step - loss: 0.6398 - acc: 0.6630 - recall: 0.6630 - precision: 0.6630 - f1_score: 0.6616 - val_loss: 0.7980 - val_acc: 0.5850 - val_recall: 0.5850 - val_precision: 0.5850 - val_f1_score: 0.6017\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58500, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 2/50\n",
      "652/652 [==============================] - 332s 509ms/step - loss: 0.5089 - acc: 0.7445 - recall: 0.7442 - precision: 0.7448 - f1_score: 0.7437 - val_loss: 1.0891 - val_acc: 0.7375 - val_recall: 0.7375 - val_precision: 0.7375 - val_f1_score: 0.6801\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.58500 to 0.73750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 3/50\n",
      "652/652 [==============================] - 332s 510ms/step - loss: 0.4982 - acc: 0.7586 - recall: 0.7586 - precision: 0.7586 - f1_score: 0.7578 - val_loss: 1.0648 - val_acc: 0.7475 - val_recall: 0.7475 - val_precision: 0.7475 - val_f1_score: 0.7174\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73750 to 0.74750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 4/50\n",
      "652/652 [==============================] - 300s 460ms/step - loss: 0.4584 - acc: 0.7883 - recall: 0.7883 - precision: 0.7883 - f1_score: 0.7884 - val_loss: 0.5643 - val_acc: 0.7250 - val_recall: 0.7250 - val_precision: 0.7250 - val_f1_score: 0.6859\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.74750\n",
      "Epoch 5/50\n",
      "652/652 [==============================] - 338s 518ms/step - loss: 0.4302 - acc: 0.8001 - recall: 0.8001 - precision: 0.8001 - f1_score: 0.8001 - val_loss: 1.3474 - val_acc: 0.4050 - val_recall: 0.4050 - val_precision: 0.4050 - val_f1_score: 0.3478\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.74750\n",
      "Epoch 6/50\n",
      "652/652 [==============================] - 340s 522ms/step - loss: 0.4348 - acc: 0.7949 - recall: 0.7949 - precision: 0.7949 - f1_score: 0.7941 - val_loss: 0.7371 - val_acc: 0.6400 - val_recall: 0.6400 - val_precision: 0.6400 - val_f1_score: 0.6549\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.74750\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000559999980032444.\n",
      "Epoch 7/50\n",
      "652/652 [==============================] - 326s 501ms/step - loss: 0.4342 - acc: 0.7890 - recall: 0.7889 - precision: 0.7890 - f1_score: 0.7883 - val_loss: 0.4657 - val_acc: 0.7700 - val_recall: 0.7700 - val_precision: 0.7719 - val_f1_score: 0.7722\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.74750 to 0.77000, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 8/50\n",
      "652/652 [==============================] - 333s 510ms/step - loss: 0.4124 - acc: 0.8064 - recall: 0.8064 - precision: 0.8064 - f1_score: 0.8061 - val_loss: 0.4774 - val_acc: 0.7800 - val_recall: 0.7800 - val_precision: 0.7800 - val_f1_score: 0.7769\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.77000 to 0.78000, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 9/50\n",
      "652/652 [==============================] - 334s 512ms/step - loss: 0.3804 - acc: 0.8383 - recall: 0.8383 - precision: 0.8383 - f1_score: 0.8382 - val_loss: 0.5956 - val_acc: 0.7100 - val_recall: 0.7100 - val_precision: 0.7100 - val_f1_score: 0.7209\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78000\n",
      "Epoch 10/50\n",
      "652/652 [==============================] - 339s 520ms/step - loss: 0.3810 - acc: 0.8232 - recall: 0.8231 - precision: 0.8231 - f1_score: 0.8230 - val_loss: 0.5777 - val_acc: 0.7325 - val_recall: 0.7325 - val_precision: 0.7325 - val_f1_score: 0.7432\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78000\n",
      "Epoch 11/50\n",
      "652/652 [==============================] - 349s 536ms/step - loss: 0.3857 - acc: 0.8149 - recall: 0.8149 - precision: 0.8149 - f1_score: 0.8145 - val_loss: 0.5300 - val_acc: 0.7725 - val_recall: 0.7725 - val_precision: 0.7725 - val_f1_score: 0.7576\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00044799996539950375.\n",
      "Epoch 12/50\n",
      "652/652 [==============================] - 321s 492ms/step - loss: 0.3205 - acc: 0.8556 - recall: 0.8556 - precision: 0.8556 - f1_score: 0.8559 - val_loss: 0.4931 - val_acc: 0.8000 - val_recall: 0.8000 - val_precision: 0.8000 - val_f1_score: 0.8000\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.78000 to 0.80000, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 13/50\n",
      "652/652 [==============================] - 334s 512ms/step - loss: 0.3394 - acc: 0.8539 - recall: 0.8539 - precision: 0.8539 - f1_score: 0.8540 - val_loss: 0.5443 - val_acc: 0.7775 - val_recall: 0.7775 - val_precision: 0.7775 - val_f1_score: 0.7659\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80000\n",
      "Epoch 14/50\n",
      "652/652 [==============================] - 321s 492ms/step - loss: 0.3263 - acc: 0.8644 - recall: 0.8644 - precision: 0.8644 - f1_score: 0.8645 - val_loss: 0.6353 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_f1_score: 0.6813\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80000\n",
      "Epoch 15/50\n",
      "652/652 [==============================] - 328s 502ms/step - loss: 0.3303 - acc: 0.8419 - recall: 0.8419 - precision: 0.8419 - f1_score: 0.8425 - val_loss: 0.5969 - val_acc: 0.7150 - val_recall: 0.7150 - val_precision: 0.7150 - val_f1_score: 0.7285\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.80000\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00035839998163282876.\n",
      "Epoch 16/50\n",
      "652/652 [==============================] - 332s 509ms/step - loss: 0.2859 - acc: 0.8756 - recall: 0.8756 - precision: 0.8756 - f1_score: 0.8758 - val_loss: 0.5031 - val_acc: 0.7900 - val_recall: 0.7900 - val_precision: 0.7900 - val_f1_score: 0.7643\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80000\n",
      "Epoch 17/50\n",
      "652/652 [==============================] - 326s 499ms/step - loss: 0.2861 - acc: 0.8805 - recall: 0.8805 - precision: 0.8805 - f1_score: 0.8805 - val_loss: 0.4959 - val_acc: 0.7925 - val_recall: 0.7925 - val_precision: 0.7925 - val_f1_score: 0.7834\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80000\n",
      "Epoch 18/50\n",
      "652/652 [==============================] - 327s 502ms/step - loss: 0.2794 - acc: 0.8770 - recall: 0.8770 - precision: 0.8770 - f1_score: 0.8767 - val_loss: 0.4844 - val_acc: 0.7825 - val_recall: 0.7825 - val_precision: 0.7825 - val_f1_score: 0.7885\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80000\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002867199946194887.\n",
      "Epoch 19/50\n",
      "652/652 [==============================] - 316s 485ms/step - loss: 0.2601 - acc: 0.8844 - recall: 0.8844 - precision: 0.8844 - f1_score: 0.8845 - val_loss: 0.4639 - val_acc: 0.8050 - val_recall: 0.8050 - val_precision: 0.8050 - val_f1_score: 0.8050\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.80000 to 0.80500, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 20/50\n",
      "652/652 [==============================] - 319s 490ms/step - loss: 0.2843 - acc: 0.8714 - recall: 0.8713 - precision: 0.8714 - f1_score: 0.8715 - val_loss: 0.4338 - val_acc: 0.8075 - val_recall: 0.8075 - val_precision: 0.8075 - val_f1_score: 0.8108\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.80500 to 0.80750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 21/50\n",
      "652/652 [==============================] - 334s 512ms/step - loss: 0.2647 - acc: 0.8900 - recall: 0.8897 - precision: 0.8900 - f1_score: 0.8900 - val_loss: 0.4671 - val_acc: 0.7750 - val_recall: 0.7750 - val_precision: 0.7750 - val_f1_score: 0.7826\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80750\n",
      "Epoch 22/50\n",
      "652/652 [==============================] - 317s 487ms/step - loss: 0.2365 - acc: 0.9041 - recall: 0.9041 - precision: 0.9041 - f1_score: 0.9041 - val_loss: 0.4615 - val_acc: 0.7850 - val_recall: 0.7850 - val_precision: 0.7850 - val_f1_score: 0.7893\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80750\n",
      "Epoch 23/50\n",
      "652/652 [==============================] - 316s 484ms/step - loss: 0.2319 - acc: 0.9028 - recall: 0.9028 - precision: 0.9028 - f1_score: 0.9028 - val_loss: 0.6721 - val_acc: 0.6950 - val_recall: 0.6950 - val_precision: 0.6950 - val_f1_score: 0.7094\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80750\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00022937599569559098.\n",
      "Epoch 24/50\n",
      "652/652 [==============================] - 329s 504ms/step - loss: 0.2330 - acc: 0.8982 - recall: 0.8982 - precision: 0.8982 - f1_score: 0.8981 - val_loss: 0.4388 - val_acc: 0.8275 - val_recall: 0.8275 - val_precision: 0.8275 - val_f1_score: 0.8225\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.80750 to 0.82750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_1.h5\n",
      "Epoch 25/50\n",
      "652/652 [==============================] - 336s 515ms/step - loss: 0.2374 - acc: 0.8903 - recall: 0.8903 - precision: 0.8903 - f1_score: 0.8903 - val_loss: 0.4126 - val_acc: 0.8225 - val_recall: 0.8225 - val_precision: 0.8225 - val_f1_score: 0.8203\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82750\n",
      "Epoch 26/50\n",
      "652/652 [==============================] - 316s 485ms/step - loss: 0.1996 - acc: 0.9141 - recall: 0.9141 - precision: 0.9141 - f1_score: 0.9141 - val_loss: 0.4537 - val_acc: 0.7975 - val_recall: 0.7975 - val_precision: 0.7975 - val_f1_score: 0.7992\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82750\n",
      "Epoch 27/50\n",
      "652/652 [==============================] - 303s 464ms/step - loss: 0.1942 - acc: 0.9219 - recall: 0.9219 - precision: 0.9219 - f1_score: 0.9219 - val_loss: 0.4632 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_f1_score: 0.8090\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.82750\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0001835007918998599.\n",
      "Epoch 28/50\n",
      "652/652 [==============================] - 341s 523ms/step - loss: 0.2059 - acc: 0.9143 - recall: 0.9143 - precision: 0.9143 - f1_score: 0.9144 - val_loss: 0.4537 - val_acc: 0.8150 - val_recall: 0.8150 - val_precision: 0.8150 - val_f1_score: 0.8124\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.82750\n",
      "Epoch 29/50\n",
      "652/652 [==============================] - 312s 479ms/step - loss: 0.1658 - acc: 0.9421 - recall: 0.9421 - precision: 0.9421 - f1_score: 0.9421 - val_loss: 0.4785 - val_acc: 0.7775 - val_recall: 0.7775 - val_precision: 0.7775 - val_f1_score: 0.7846\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82750\n",
      "Epoch 30/50\n",
      "652/652 [==============================] - 340s 521ms/step - loss: 0.1674 - acc: 0.9279 - recall: 0.9265 - precision: 0.9278 - f1_score: 0.9279 - val_loss: 0.5983 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_f1_score: 0.7617\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82750\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00014680062886327506.\n",
      "Epoch 31/50\n",
      "652/652 [==============================] - 334s 513ms/step - loss: 0.1474 - acc: 0.9382 - recall: 0.9382 - precision: 0.9382 - f1_score: 0.9382 - val_loss: 0.4528 - val_acc: 0.7950 - val_recall: 0.7950 - val_precision: 0.7950 - val_f1_score: 0.7970\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.82750\n",
      "Epoch 32/50\n",
      "652/652 [==============================] - 321s 493ms/step - loss: 0.1604 - acc: 0.9383 - recall: 0.9383 - precision: 0.9383 - f1_score: 0.9383 - val_loss: 0.4569 - val_acc: 0.8225 - val_recall: 0.8225 - val_precision: 0.8225 - val_f1_score: 0.8236\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82750\n",
      "Epoch 33/50\n",
      "652/652 [==============================] - 342s 523ms/step - loss: 0.1610 - acc: 0.9378 - recall: 0.9373 - precision: 0.9378 - f1_score: 0.9375 - val_loss: 0.5300 - val_acc: 0.7800 - val_recall: 0.7800 - val_precision: 0.7820 - val_f1_score: 0.7881\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.82750\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00011744049843400718.\n",
      "Epoch 34/50\n",
      "652/652 [==============================] - 322s 494ms/step - loss: 0.1610 - acc: 0.9371 - recall: 0.9371 - precision: 0.9371 - f1_score: 0.9370 - val_loss: 0.4872 - val_acc: 0.8250 - val_recall: 0.8250 - val_precision: 0.8250 - val_f1_score: 0.8214\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82750\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Warning! Model path already exists.\n",
      "Epoch 1/50\n",
      "652/652 [==============================] - 353s 473ms/step - loss: 0.6463 - acc: 0.6415 - recall: 0.6415 - precision: 0.6415 - f1_score: 0.6373 - val_loss: 16.8227 - val_acc: 0.2925 - val_recall: 0.2925 - val_precision: 0.2925 - val_f1_score: 0.1514\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 2/50\n",
      "652/652 [==============================] - 321s 492ms/step - loss: 0.5468 - acc: 0.7397 - recall: 0.7381 - precision: 0.7393 - f1_score: 0.7367 - val_loss: 0.7290 - val_acc: 0.6075 - val_recall: 0.6075 - val_precision: 0.6075 - val_f1_score: 0.6265\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29250 to 0.60750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 3/50\n",
      "652/652 [==============================] - 334s 513ms/step - loss: 0.5178 - acc: 0.7385 - recall: 0.7385 - precision: 0.7385 - f1_score: 0.7370 - val_loss: 0.5819 - val_acc: 0.7350 - val_recall: 0.7350 - val_precision: 0.7350 - val_f1_score: 0.7487\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.60750 to 0.73500, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 4/50\n",
      "652/652 [==============================] - 308s 472ms/step - loss: 0.4773 - acc: 0.7724 - recall: 0.7713 - precision: 0.7721 - f1_score: 0.7714 - val_loss: 0.4974 - val_acc: 0.7925 - val_recall: 0.7925 - val_precision: 0.7925 - val_f1_score: 0.7724\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73500 to 0.79250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 5/50\n",
      "652/652 [==============================] - 334s 511ms/step - loss: 0.4018 - acc: 0.8150 - recall: 0.8150 - precision: 0.8150 - f1_score: 0.8151 - val_loss: 0.5555 - val_acc: 0.7100 - val_recall: 0.7100 - val_precision: 0.7100 - val_f1_score: 0.7251\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79250\n",
      "Epoch 6/50\n",
      "652/652 [==============================] - 351s 539ms/step - loss: 0.4263 - acc: 0.8054 - recall: 0.8054 - precision: 0.8065 - f1_score: 0.8052 - val_loss: 0.4498 - val_acc: 0.7975 - val_recall: 0.7975 - val_precision: 0.7975 - val_f1_score: 0.8003\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.79250 to 0.79750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 7/50\n",
      "652/652 [==============================] - 327s 501ms/step - loss: 0.4090 - acc: 0.8078 - recall: 0.8078 - precision: 0.8078 - f1_score: 0.8072 - val_loss: 0.9263 - val_acc: 0.5725 - val_recall: 0.5725 - val_precision: 0.5725 - val_f1_score: 0.5854\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79750\n",
      "Epoch 8/50\n",
      "652/652 [==============================] - 339s 520ms/step - loss: 0.4191 - acc: 0.7983 - recall: 0.7983 - precision: 0.7983 - f1_score: 0.7983 - val_loss: 0.4563 - val_acc: 0.7850 - val_recall: 0.7850 - val_precision: 0.7850 - val_f1_score: 0.7887\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79750\n",
      "Epoch 9/50\n",
      "652/652 [==============================] - 325s 499ms/step - loss: 0.4088 - acc: 0.8080 - recall: 0.8078 - precision: 0.8079 - f1_score: 0.8078 - val_loss: 0.6195 - val_acc: 0.6100 - val_recall: 0.6100 - val_precision: 0.6100 - val_f1_score: 0.6291\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79750\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000559999980032444.\n",
      "Epoch 10/50\n",
      "652/652 [==============================] - 335s 514ms/step - loss: 0.3952 - acc: 0.8137 - recall: 0.8137 - precision: 0.8137 - f1_score: 0.8134 - val_loss: 0.4474 - val_acc: 0.8075 - val_recall: 0.8075 - val_precision: 0.8075 - val_f1_score: 0.8049\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.79750 to 0.80750, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 11/50\n",
      "652/652 [==============================] - 338s 518ms/step - loss: 0.3637 - acc: 0.8257 - recall: 0.8257 - precision: 0.8257 - f1_score: 0.8257 - val_loss: 0.5212 - val_acc: 0.7300 - val_recall: 0.7300 - val_precision: 0.7300 - val_f1_score: 0.7437\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80750\n",
      "Epoch 12/50\n",
      "652/652 [==============================] - 314s 482ms/step - loss: 0.3705 - acc: 0.8314 - recall: 0.8314 - precision: 0.8314 - f1_score: 0.8315 - val_loss: 0.4101 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_f1_score: 0.7994\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80750 to 0.81250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 13/50\n",
      "652/652 [==============================] - 333s 510ms/step - loss: 0.3194 - acc: 0.8522 - recall: 0.8522 - precision: 0.8522 - f1_score: 0.8523 - val_loss: 0.4054 - val_acc: 0.8100 - val_recall: 0.8100 - val_precision: 0.8100 - val_f1_score: 0.8141\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.81250\n",
      "Epoch 14/50\n",
      "652/652 [==============================] - 320s 490ms/step - loss: 0.3404 - acc: 0.8451 - recall: 0.8451 - precision: 0.8451 - f1_score: 0.8450 - val_loss: 0.3786 - val_acc: 0.8400 - val_recall: 0.8400 - val_precision: 0.8421 - val_f1_score: 0.8414\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.81250 to 0.84000, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 15/50\n",
      "652/652 [==============================] - 335s 514ms/step - loss: 0.3390 - acc: 0.8471 - recall: 0.8471 - precision: 0.8474 - f1_score: 0.8470 - val_loss: 0.3848 - val_acc: 0.8425 - val_recall: 0.8425 - val_precision: 0.8425 - val_f1_score: 0.8447\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.84000 to 0.84250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_2.h5\n",
      "Epoch 16/50\n",
      "652/652 [==============================] - 317s 486ms/step - loss: 0.3390 - acc: 0.8502 - recall: 0.8496 - precision: 0.8501 - f1_score: 0.8500 - val_loss: 0.4145 - val_acc: 0.8350 - val_recall: 0.8350 - val_precision: 0.8350 - val_f1_score: 0.8308\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.84250\n",
      "Epoch 17/50\n",
      "652/652 [==============================] - 337s 517ms/step - loss: 0.3366 - acc: 0.8502 - recall: 0.8502 - precision: 0.8502 - f1_score: 0.8503 - val_loss: 0.4025 - val_acc: 0.8275 - val_recall: 0.8250 - val_precision: 0.8271 - val_f1_score: 0.8194\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84250\n",
      "Epoch 18/50\n",
      "652/652 [==============================] - 327s 502ms/step - loss: 0.3170 - acc: 0.8501 - recall: 0.8501 - precision: 0.8501 - f1_score: 0.8502 - val_loss: 0.3768 - val_acc: 0.8275 - val_recall: 0.8275 - val_precision: 0.8275 - val_f1_score: 0.8282\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.84250\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00044799996539950375.\n",
      "Epoch 19/50\n",
      "652/652 [==============================] - 335s 514ms/step - loss: 0.3071 - acc: 0.8545 - recall: 0.8545 - precision: 0.8545 - f1_score: 0.8545 - val_loss: 0.3980 - val_acc: 0.8150 - val_recall: 0.8150 - val_precision: 0.8150 - val_f1_score: 0.7966\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.84250\n",
      "Epoch 20/50\n",
      "652/652 [==============================] - 308s 473ms/step - loss: 0.2574 - acc: 0.8930 - recall: 0.8930 - precision: 0.8930 - f1_score: 0.8931 - val_loss: 0.3752 - val_acc: 0.8375 - val_recall: 0.8375 - val_precision: 0.8375 - val_f1_score: 0.8386\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.84250\n",
      "Epoch 21/50\n",
      "652/652 [==============================] - 301s 462ms/step - loss: 0.2763 - acc: 0.8812 - recall: 0.8812 - precision: 0.8812 - f1_score: 0.8812 - val_loss: 0.3708 - val_acc: 0.8350 - val_recall: 0.8350 - val_precision: 0.8350 - val_f1_score: 0.8355\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.84250\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00035839998163282876.\n",
      "Epoch 22/50\n",
      "652/652 [==============================] - 332s 508ms/step - loss: 0.2690 - acc: 0.8862 - recall: 0.8862 - precision: 0.8870 - f1_score: 0.8862 - val_loss: 0.4028 - val_acc: 0.8325 - val_recall: 0.8325 - val_precision: 0.8325 - val_f1_score: 0.8291\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.84250\n",
      "Epoch 23/50\n",
      "652/652 [==============================] - 344s 528ms/step - loss: 0.2575 - acc: 0.8926 - recall: 0.8926 - precision: 0.8926 - f1_score: 0.8926 - val_loss: 0.3854 - val_acc: 0.8225 - val_recall: 0.8225 - val_precision: 0.8225 - val_f1_score: 0.8289\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.84250\n",
      "Epoch 24/50\n",
      "652/652 [==============================] - 354s 543ms/step - loss: 0.2508 - acc: 0.8830 - recall: 0.8830 - precision: 0.8830 - f1_score: 0.8829 - val_loss: 0.4101 - val_acc: 0.8200 - val_recall: 0.8200 - val_precision: 0.8200 - val_f1_score: 0.8268\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.84250\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002867199946194887.\n",
      "Epoch 25/50\n",
      "652/652 [==============================] - 326s 501ms/step - loss: 0.2410 - acc: 0.8998 - recall: 0.8998 - precision: 0.8998 - f1_score: 0.8995 - val_loss: 0.4187 - val_acc: 0.8075 - val_recall: 0.8075 - val_precision: 0.8075 - val_f1_score: 0.8162\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.84250\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Warning! Model path already exists.\n",
      "Epoch 1/50\n",
      "652/652 [==============================] - 366s 494ms/step - loss: 0.6245 - acc: 0.6525 - recall: 0.6525 - precision: 0.6525 - f1_score: 0.6501 - val_loss: 0.8076 - val_acc: 0.7525 - val_recall: 0.7525 - val_precision: 0.7525 - val_f1_score: 0.6511\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_3.h5\n",
      "Epoch 2/50\n",
      "652/652 [==============================] - 325s 499ms/step - loss: 0.4952 - acc: 0.7611 - recall: 0.7611 - precision: 0.7611 - f1_score: 0.7598 - val_loss: 0.8072 - val_acc: 0.6450 - val_recall: 0.6450 - val_precision: 0.6450 - val_f1_score: 0.6681\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.75250\n",
      "Epoch 3/50\n",
      "652/652 [==============================] - 333s 510ms/step - loss: 0.4667 - acc: 0.7783 - recall: 0.7783 - precision: 0.7783 - f1_score: 0.7779 - val_loss: 0.6339 - val_acc: 0.6725 - val_recall: 0.6725 - val_precision: 0.6725 - val_f1_score: 0.6924\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75250\n",
      "Epoch 4/50\n",
      "652/652 [==============================] - 322s 494ms/step - loss: 0.4607 - acc: 0.7883 - recall: 0.7883 - precision: 0.7883 - f1_score: 0.7870 - val_loss: 0.4405 - val_acc: 0.7925 - val_recall: 0.7925 - val_precision: 0.7925 - val_f1_score: 0.7700\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.75250 to 0.79250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_3.h5\n",
      "Epoch 5/50\n",
      "652/652 [==============================] - 344s 528ms/step - loss: 0.4590 - acc: 0.7872 - recall: 0.7872 - precision: 0.7872 - f1_score: 0.7869 - val_loss: 0.8021 - val_acc: 0.5050 - val_recall: 0.5050 - val_precision: 0.5050 - val_f1_score: 0.5283\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79250\n",
      "Epoch 6/50\n",
      "652/652 [==============================] - 329s 504ms/step - loss: 0.4301 - acc: 0.8001 - recall: 0.8001 - precision: 0.8001 - f1_score: 0.7990 - val_loss: 0.9830 - val_acc: 0.4800 - val_recall: 0.4800 - val_precision: 0.4800 - val_f1_score: 0.4825\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79250\n",
      "Epoch 7/50\n",
      "652/652 [==============================] - 360s 553ms/step - loss: 0.4189 - acc: 0.8067 - recall: 0.8067 - precision: 0.8067 - f1_score: 0.8066 - val_loss: 0.3776 - val_acc: 0.8525 - val_recall: 0.8525 - val_precision: 0.8525 - val_f1_score: 0.8502\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.79250 to 0.85250, saving model to /app/_data/models/EffB7_2class_1/EffB7_2cl_3.h5\n",
      "Epoch 8/50\n",
      "652/652 [==============================] - 372s 570ms/step - loss: 0.4068 - acc: 0.8162 - recall: 0.8162 - precision: 0.8162 - f1_score: 0.8163 - val_loss: 0.5070 - val_acc: 0.7925 - val_recall: 0.7925 - val_precision: 0.7925 - val_f1_score: 0.7572\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.85250\n",
      "Epoch 9/50\n",
      "274/652 [===========>..................] - ETA: 3:13 - loss: 0.4229 - acc: 0.8192 - recall: 0.8192 - precision: 0.8192 - f1_score: 0.8191"
     ]
    }
   ],
   "source": [
    "for n in range(5):\n",
    "    val = df.loc[val_ids[n]].sample(frac=1, random_state=base_config[\"EFFB7\"][\"SEED\"])\n",
    "    train = pd.concat(\n",
    "        [\n",
    "            df.loc[\n",
    "                train_ids[n],\n",
    "                [\"image\", \"class\", \"modality\", \"PatientSex\", \"BodyPartExamined\"],\n",
    "            ],\n",
    "            labels.sample(3000),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "        axis=0,\n",
    "    ).sample(frac=1, random_state=base_config[\"EFFB7\"][\"SEED\"])\n",
    "\n",
    "    tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "    gen_train = Generator(\n",
    "        df=train,\n",
    "        batch_size=base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "        seed=base_config[\"EFFB7\"][\"SEED\"],\n",
    "        img_size=base_config[\"EFFB7\"][\"IMG_SIZE\"],\n",
    "        prepared_img_path=\"/app/_data/train_jpg_600/\",\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        hard_augment=True,\n",
    "        n_inputs=2,\n",
    "        n_classes=2,\n",
    "    )\n",
    "    gen_valid = Generator(\n",
    "        df=val,\n",
    "        batch_size=base_config[\"EFFB7\"][\"BATCH_SIZE\"],\n",
    "        seed=base_config[\"EFFB7\"][\"SEED\"],\n",
    "        img_size=base_config[\"EFFB7\"][\"IMG_SIZE\"],\n",
    "        prepared_img_path=\"/app/_data/train_jpg_600/\",\n",
    "        shuffle=False,\n",
    "        augment=False,\n",
    "        hard_augment=False,\n",
    "        n_inputs=2,\n",
    "        n_classes=2,\n",
    "    )\n",
    "\n",
    "    train_sample = gen_train.__getitem__(10)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.title(train_sample[1][i])\n",
    "        plt.imshow(train_sample[0][\"img\"][i])\n",
    "\n",
    "    model = GetModel(\n",
    "        model_name=\"EFFB7\",\n",
    "        n_inputs=2,\n",
    "        lr=0.0007,\n",
    "        activation_func=\"softmax\",\n",
    "        weights=None,\n",
    "        n_classes=2,\n",
    "    ).get_model()\n",
    "    policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "    keras.mixed_precision.experimental.set_policy(policy)\n",
    "\n",
    "    callbacks = GetModel(\"EFFB7\", n_classes=1).make_callback(\n",
    "        model_path=\"/app/_data/models/EffB7_2class_1/\",\n",
    "        model_name=\"EffB7_2cl_\" + str(n) + \".h5\",\n",
    "        tensorboard_path=\"/app/.tensorboard/EffB7_2cl11_\" + str(n),\n",
    "        patience_ES=10,\n",
    "        patience_RLR=3,\n",
    "        factor_LR=0.8,\n",
    "        metric_for_monitor=\"val_acc\",\n",
    "        metric_mode=\"max\",\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_valid,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=train.shape[0] // base_config[\"EFFB7\"][\"BATCH_SIZE\"] // 3,\n",
    "        validation_steps=val.shape[0] // base_config[\"EFFB7\"][\"BATCH_SIZE\"] // 3,\n",
    "        verbose=1,\n",
    "        workers=20,\n",
    "        max_queue_size=500,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28192e-b86f-47e8-98bf-55f334bcd6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90af53-1331-4198-a9b3-00a16f69411c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
