{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bccb46a-223a-4f5c-bb17-bf7405466632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28c2145-9a19-4e77-ad92-b87f4fa0f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    def prepare_data(\n",
    "        data_path, path_to_save, train_mode=True, n_train_sample=10, voi_lut=False\n",
    "    ):\n",
    "        if not os.path.exists(path_to_save):\n",
    "            os.mkdir(path_to_save)\n",
    "        test_df = pd.DataFrame()\n",
    "        if train_mode:\n",
    "            p = os.listdir(data_path)[:n_train_sample]\n",
    "        else:\n",
    "            p = os.listdir(data_path)\n",
    "        for folder1 in tqdm(p):\n",
    "            for folder2 in os.listdir(data_path + folder1):\n",
    "                path = os.path.join(data_path, folder1, folder2)\n",
    "                for img_file in os.listdir(path):\n",
    "                    img_path = os.path.join(path, img_file)\n",
    "                    test_df.loc[img_file, \"path\"] = img_path\n",
    "                    data_file = dicom.dcmread(img_path)\n",
    "                    test_df.loc[img_file, \"StudyInstanceUID\"] = folder1\n",
    "                    test_df.loc[img_file, \"id_image\"] = img_file[:-4]\n",
    "                    test_df.loc[img_file, \"modality\"] = data_file.Modality\n",
    "                    test_df.loc[img_file, \"PatientSex\"] = data_file.PatientSex\n",
    "                    test_df.loc[\n",
    "                        img_file, \"BodyPartExamined\"\n",
    "                    ] = data_file.BodyPartExamined\n",
    "                    test_df.loc[\n",
    "                        img_file, \"PhotometricInterpretation\"\n",
    "                    ] = data_file.PhotometricInterpretation\n",
    "                    test_df.loc[img_file, \"width\"] = data_file.pixel_array.shape[1]\n",
    "                    test_df.loc[img_file, \"height\"] = data_file.pixel_array.shape[0]\n",
    "                    if voi_lut:\n",
    "                        img = apply_voi_lut(data_file.pixel_array, data_file)\n",
    "                    else:\n",
    "                        img = data_file.pixel_array\n",
    "                    if data_file.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "                        img = img.max() - img\n",
    "                    img = (img - img.min()) / (img.max() - img.min())\n",
    "                    img = (np.array(img) * 255).astype(\"uint8\")\n",
    "                    img = np.stack([img, img, img], axis=-1)\n",
    "                    img = Image.fromarray(img)\n",
    "                    img.save(path_to_save + img_file[:-4] + \".jpg\")\n",
    "        test_df = test_df.reset_index(drop=True)\n",
    "        test_df[\"path\"] = test_df[\"path\"].str.replace(\"\\../\", \"/kaggle/\")\n",
    "        return test_df\n",
    "\n",
    "    def make_classification(\n",
    "        test_df_,\n",
    "        jpg_path,\n",
    "        metadata_path,\n",
    "        model_path,\n",
    "        thres=0.4,\n",
    "        voi_lut=True,\n",
    "        obj_det=True,\n",
    "        classification=True,\n",
    "        img_size=600,\n",
    "        img_from_folder=True,\n",
    "    ):\n",
    "        sub_study = pd.DataFrame(columns=[\"id\", \"PredictionString\"])\n",
    "        gen = Generator(\n",
    "            df=test_df_,\n",
    "            img_size=img_size,\n",
    "            jpg_path=jpg_path,\n",
    "            metadata_path=metadata_path,\n",
    "            voi_lut=voi_lut,\n",
    "            img_from_folder = img_from_folder,\n",
    "            batch_size=1,\n",
    "        )\n",
    "        print(gen.__getitem__(2)[\"img\"].shape)\n",
    "        plt.imshow(gen.__getitem__(1)[\"img\"][0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "        # check only object detection score\n",
    "        if not classification:\n",
    "            for ix in test_df_.StudyInstanceUID.unique().tolist():\n",
    "                sub_study = sub_study.append(\n",
    "                    {\n",
    "                        \"id\": ix + \"_study\",\n",
    "                        \"PredictionString\": \"negative 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1 atypical 1 0 0 1 1\",\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "        # classification\n",
    "        else:\n",
    "            eff_models = []\n",
    "            for file in os.listdir(model_path):\n",
    "                if \".h5\" in file:\n",
    "                    eff_models.append(keras.models.load_model(model_path + file))\n",
    "\n",
    "            test_df_.study_pred = np.nan\n",
    "            count_thres = len(eff_models) // 2 + 1\n",
    "\n",
    "            for ix in tqdm(test_df_.index.tolist()):\n",
    "                data = gen.__getitem__(ix)\n",
    "                predictions = []\n",
    "                for i in range(len(eff_models)):\n",
    "                    pred = eff_models[i].predict(data)[0]\n",
    "                    test_df_.loc[ix, \"negative\"] = np.round(pred[0], 5)\n",
    "                    test_df_.loc[ix, \"typical\"] = np.round(pred[1], 5)\n",
    "                    test_df_.loc[ix, \"indeterminate\"] = np.round(pred[2], 5)\n",
    "                    test_df_.loc[ix, \"atypical\"] = np.round(pred[3], 5)\n",
    "                    predictions.extend([labels[i] for i in range(4) if pred[i] > thres])\n",
    "                test_df_.loc[ix, \"study_pred\"] = \" \".join(\n",
    "                    [\n",
    "                        x\n",
    "                        for x in list(set(predictions))\n",
    "                        if predictions.count(x) >= count_thres\n",
    "                    ]\n",
    "                )\n",
    "            test_df_[\"study_pred\"] = test_df_[\"study_pred\"].replace(\"\", \"negative\")\n",
    "            test_df_[\"study_pred\"] = test_df_[\"study_pred\"].fillna(\"negative\")\n",
    "\n",
    "            # PredictionString in format 'label threshold 0 0 1 1'\n",
    "            groupped_df = test_df_.groupby(\"StudyInstanceUID\")[\n",
    "                [\"negative\", \"typical\", \"indeterminate\", \"atypical\"]\n",
    "            ].mean()\n",
    "            for ix in groupped_df.index.tolist():\n",
    "                predictions = list(map(str, (np.round(groupped_df.loc[ix].values, 5))))\n",
    "                pred = \" \".join(\n",
    "                    [\n",
    "                        labels[i] + \" \" + predictions[i] + \" 0 0 1 1\"\n",
    "                        for i in range(len(labels))\n",
    "                    ]\n",
    "                )\n",
    "                sub_study = sub_study.append(\n",
    "                    {\"id\": ix + \"_study\", \"PredictionString\": pred}, ignore_index=True\n",
    "                )\n",
    "\n",
    "        # check only classification score\n",
    "        if not obj_det:\n",
    "            sub_image = pd.DataFrame(columns=[\"id\", \"PredictionString\"])\n",
    "            for img_name in test_df_.id_image.tolist():\n",
    "                sub_image = sub_image.append(\n",
    "                    {\"id\": img_name + \"_image\", \"PredictionString\": \"none 1 0 0 1 1\"},\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            return sub_study, sub_image, test_df_\n",
    "        return sub_study, test_df_\n",
    "\n",
    "    def make_bbox_df(test_df_, SAVE_BBOX_PATH):\n",
    "        sub_image = pd.DataFrame(columns=[\"id\", \"PredictionString\"])\n",
    "        for file in os.listdir(SAVE_BBOX_PATH + \"labels/\"):\n",
    "            img_name = file[:-4]\n",
    "            w = test_df_[test_df_[\"id_image\"] == img_name][\"width\"].values[0]\n",
    "            h = test_df_[test_df_[\"id_image\"] == img_name][\"height\"].values[0]\n",
    "            with open(SAVE_BBOX_PATH + \"labels/\" + file, \"r\") as f:\n",
    "                ls = f.read()\n",
    "                ls = re.sub(r\"[\\n]\", \" \", ls).strip().split()\n",
    "                ls = list(map(float, ls))\n",
    "                list_pred = []\n",
    "                for i in range(0, len(ls), 6):\n",
    "                    x_c = ls[i + 1]\n",
    "                    y_c = ls[i + 2]\n",
    "                    w_p = ls[i + 3]\n",
    "                    h_p = ls[i + 4]\n",
    "                    conf = ls[i + 5]\n",
    "                    xmin = int((x_c - w_p / 2) * w)\n",
    "                    ymin = int((y_c - h_p / 2) * h)\n",
    "                    xmax = int((x_c + w_p / 2) * w)\n",
    "                    ymax = int((y_c + h_p / 2) * h)\n",
    "                    list_pred.extend([\"opacity\", conf, xmin, ymin, xmax, ymax])\n",
    "                sub_image = sub_image.append(\n",
    "                    {\n",
    "                        \"id\": img_name + \"_image\",\n",
    "                        \"PredictionString\": \" \".join(list(map(str, list_pred))),\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "        for img_name in test_df_.id_image.tolist():\n",
    "            if img_name + \"_image\" not in sub_image.id.tolist():\n",
    "                sub_image = sub_image.append(\n",
    "                    {\"id\": img_name + \"_image\", \"PredictionString\": \"none 1 0 0 1 1\"},\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "        return sub_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52469f72-52cb-4b71-8873-37416fb5df0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.86it/s]\n",
      "<ipython-input-3-0716b349b9d4>:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_df[\"path\"] = test_df[\"path\"].str.replace(\"\\../\", \"/kaggle/\")\n"
     ]
    }
   ],
   "source": [
    "test_df = Test.prepare_data(\n",
    "    data_path=\"/app/_data/test/\",\n",
    "    path_to_save=\"/app/_data/tmp/\",\n",
    "    voi_lut=True,\n",
    "    train_mode=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81388041-111e-408f-a9d4-84ae37925c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        img_size,\n",
    "        jpg_path,\n",
    "        metadata_path,\n",
    "        img_from_folder=True,\n",
    "        voi_lut=False,\n",
    "        batch_size=1,\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.voi_lut = voi_lut\n",
    "        self.jpg_path = jpg_path\n",
    "        self.metadata_path = metadata_path\n",
    "        self.img_from_folder = img_from_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0] // self.batch_size\n",
    "\n",
    "    def img_from_dicom(self, img_path, img_type):\n",
    "        data_file = dicom.dcmread(img_path)\n",
    "        if self.voi_lut:\n",
    "            img = apply_voi_lut(data_file.pixel_array, data_file)\n",
    "        else:\n",
    "            img = data_file.pixel_array\n",
    "        if img_type == \"MONOCHROME1\":\n",
    "            img = img.max() - img\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        img = (np.array(img) * 255).astype(\"uint8\")\n",
    "        img = np.stack([img, img, img], axis=-1)\n",
    "        img = tf.image.resize(\n",
    "            img,\n",
    "            (self.img_size, self.img_size),\n",
    "        )\n",
    "        img = tf.cast(img, tf.uint8)\n",
    "        return img.numpy()\n",
    "\n",
    "    def make_img(self, img_path, img_type):\n",
    "        img_name = img_path.split(\"/\")[-1].split(\".dcm\")[0]\n",
    "        if self.img_from_folder:\n",
    "            try:\n",
    "                img = tf.io.read_file(self.jpg_path + img_name + \".jpg\")\n",
    "                img = tf.image.decode_jpeg(img, channels=3)\n",
    "                img = tf.image.resize(\n",
    "                    img,\n",
    "                    (self.img_size, self.img_size),\n",
    "                )\n",
    "                img = tf.cast(img, tf.uint8)\n",
    "                img = img.numpy()\n",
    "            except:\n",
    "                img = self.img_from_dicom(img_path, img_type)\n",
    "        else:\n",
    "            img = self.img_from_dicom(img_path, img_type)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def _get_one(self, ix):\n",
    "        img_name = self.df.loc[ix, \"id_image\"]\n",
    "        img_path = self.df.loc[ix, \"path\"]\n",
    "        modality = self.df.loc[ix, \"modality\"]\n",
    "        PatientSex = self.df.loc[ix, \"PatientSex\"]\n",
    "        body_part = self.df.loc[ix, \"BodyPartExamined\"]\n",
    "        img_type = self.df.loc[ix, \"PhotometricInterpretation\"]\n",
    "        img = self.make_img(img_path, img_type)\n",
    "        x = {}\n",
    "        with open(self.metadata_path, \"r\") as f:\n",
    "            dict_metadata = json.load(f)\n",
    "\n",
    "        patient_sex_x = np.zeros(len(dict_metadata[\"PatientSex\"]), dtype=\"uint8\")\n",
    "        body_part_x = np.zeros(len(dict_metadata[\"BodyPartExamined\"]), dtype=\"uint8\")\n",
    "        modality_x = np.zeros(len(dict_metadata[\"PatientSex\"]), dtype=\"uint8\")\n",
    "\n",
    "        if PatientSex in dict_metadata[\"PatientSex\"].keys():\n",
    "            patient_sex_x[dict_metadata[\"PatientSex\"][PatientSex]] = 1\n",
    "        else:\n",
    "            patient_sex_x[dict_metadata[\"PatientSex\"][\"unknown\"]] = 1\n",
    "        if body_part in dict_metadata[\"BodyPartExamined\"].keys():\n",
    "            body_part_x[dict_metadata[\"BodyPartExamined\"][body_part]] = 1\n",
    "        else:\n",
    "            body_part_x[dict_metadata[\"BodyPartExamined\"][\"unknown\"]] = 1\n",
    "        if modality in dict_metadata[\"modality\"].keys():\n",
    "            modality_x[dict_metadata[\"modality\"][modality]] = 1\n",
    "        else:\n",
    "            modality_x[dict_metadata[\"modality\"][\"unknown\"]] = 1\n",
    "        x[\"img\"] = img\n",
    "        x[\"data\"] = np.concatenate([patient_sex_x, body_part_x, modality_x])\n",
    "        y = np.zeros(4, dtype=\"uint8\")\n",
    "        return x, y\n",
    "\n",
    "    def __getitem__(self, batch_ix):\n",
    "\n",
    "        x, y = {}, []\n",
    "        b_x_img = []\n",
    "        b_x_data = []\n",
    "        for i in range(self.batch_size):\n",
    "            x_dict, y_ = self._get_one(i + self.batch_size * batch_ix)\n",
    "            b_x_img.append(x_dict[\"img\"])\n",
    "            b_x_data.append(x_dict[\"data\"])\n",
    "            y.append(y_)\n",
    "        x[\"img\"] = np.array(b_x_img)\n",
    "        x[\"data\"] = np.array(b_x_data)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2cc67d8-2522-4fbd-9498-00ffc3a81960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>id_image</th>\n",
       "      <th>modality</th>\n",
       "      <th>PatientSex</th>\n",
       "      <th>BodyPartExamined</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/app/_data/test/fe64182ae21d/d56579abcb25/a82c...</td>\n",
       "      <td>fe64182ae21d</td>\n",
       "      <td>a82ca8f37fb6</td>\n",
       "      <td>CR</td>\n",
       "      <td>F</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>4248.0</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/app/_data/test/6117058c3931/d51d2a5e7f7a/b74f...</td>\n",
       "      <td>6117058c3931</td>\n",
       "      <td>b74f81d65e79</td>\n",
       "      <td>DX</td>\n",
       "      <td>M</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/app/_data/test/b83eaac8a377/326c25201eea/1c13...</td>\n",
       "      <td>b83eaac8a377</td>\n",
       "      <td>1c13336fc8a9</td>\n",
       "      <td>DX</td>\n",
       "      <td>M</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>2520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/app/_data/test/9fab41ffbc39/5b8d372f6714/fa0c...</td>\n",
       "      <td>9fab41ffbc39</td>\n",
       "      <td>fa0c84ee4577</td>\n",
       "      <td>CR</td>\n",
       "      <td>F</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME1</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/app/_data/test/4e4ee0341fab/70ae5f9ad500/dc68...</td>\n",
       "      <td>4e4ee0341fab</td>\n",
       "      <td>dc6834a1efa6</td>\n",
       "      <td>CR</td>\n",
       "      <td>F</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>2597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/app/_data/test/5a74a91d9877/25998b541988/eff9...</td>\n",
       "      <td>5a74a91d9877</td>\n",
       "      <td>eff9f15c7e9b</td>\n",
       "      <td>DX</td>\n",
       "      <td>M</td>\n",
       "      <td>TORAX</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>3712.0</td>\n",
       "      <td>3395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/app/_data/test/e43ccd956545/64ed4d9be391/87d8...</td>\n",
       "      <td>e43ccd956545</td>\n",
       "      <td>87d8baf120a6</td>\n",
       "      <td>CR</td>\n",
       "      <td>M</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/app/_data/test/a8fe3043e449/73453ff7181d/64ea...</td>\n",
       "      <td>a8fe3043e449</td>\n",
       "      <td>64ea82b1343f</td>\n",
       "      <td>DX</td>\n",
       "      <td>M</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>4256.0</td>\n",
       "      <td>3488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/app/_data/test/1d8b4a15135f/cfe99f0be9cb/acc3...</td>\n",
       "      <td>1d8b4a15135f</td>\n",
       "      <td>acc3e6eff7c8</td>\n",
       "      <td>DX</td>\n",
       "      <td>M</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>2837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/app/_data/test/994aa93b88d6/2138dd9d65e4/36ba...</td>\n",
       "      <td>994aa93b88d6</td>\n",
       "      <td>36ba388a18df</td>\n",
       "      <td>CR</td>\n",
       "      <td>M</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>4248.0</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path StudyInstanceUID  \\\n",
       "0  /app/_data/test/fe64182ae21d/d56579abcb25/a82c...     fe64182ae21d   \n",
       "1  /app/_data/test/6117058c3931/d51d2a5e7f7a/b74f...     6117058c3931   \n",
       "2  /app/_data/test/b83eaac8a377/326c25201eea/1c13...     b83eaac8a377   \n",
       "3  /app/_data/test/9fab41ffbc39/5b8d372f6714/fa0c...     9fab41ffbc39   \n",
       "4  /app/_data/test/4e4ee0341fab/70ae5f9ad500/dc68...     4e4ee0341fab   \n",
       "5  /app/_data/test/5a74a91d9877/25998b541988/eff9...     5a74a91d9877   \n",
       "6  /app/_data/test/e43ccd956545/64ed4d9be391/87d8...     e43ccd956545   \n",
       "7  /app/_data/test/a8fe3043e449/73453ff7181d/64ea...     a8fe3043e449   \n",
       "8  /app/_data/test/1d8b4a15135f/cfe99f0be9cb/acc3...     1d8b4a15135f   \n",
       "9  /app/_data/test/994aa93b88d6/2138dd9d65e4/36ba...     994aa93b88d6   \n",
       "\n",
       "       id_image modality PatientSex BodyPartExamined  \\\n",
       "0  a82ca8f37fb6       CR          F            CHEST   \n",
       "1  b74f81d65e79       DX          M            CHEST   \n",
       "2  1c13336fc8a9       DX          M            CHEST   \n",
       "3  fa0c84ee4577       CR          F            CHEST   \n",
       "4  dc6834a1efa6       CR          F            CHEST   \n",
       "5  eff9f15c7e9b       DX          M            TORAX   \n",
       "6  87d8baf120a6       CR          M            CHEST   \n",
       "7  64ea82b1343f       DX          M            CHEST   \n",
       "8  acc3e6eff7c8       DX          M            CHEST   \n",
       "9  36ba388a18df       CR          M            CHEST   \n",
       "\n",
       "  PhotometricInterpretation   width  height  \n",
       "0               MONOCHROME2  4248.0  3480.0  \n",
       "1               MONOCHROME2  3032.0  3032.0  \n",
       "2               MONOCHROME2  3032.0  2520.0  \n",
       "3               MONOCHROME1  4240.0  3480.0  \n",
       "4               MONOCHROME2  2621.0  2597.0  \n",
       "5               MONOCHROME2  3712.0  3395.0  \n",
       "6               MONOCHROME2  4240.0  3480.0  \n",
       "7               MONOCHROME2  4256.0  3488.0  \n",
       "8               MONOCHROME2  2979.0  2837.0  \n",
       "9               MONOCHROME2  4248.0  3480.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d770fa0c-eb9a-46c0-892d-0b2a9efcbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(\n",
    "    df=test_df,\n",
    "    img_size=600,\n",
    "    jpg_path=\"/app/_data/tmp/\",\n",
    "    metadata_path=\"/app/_data/dict_metadata.json\",\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0531463c-69bf-45fc-b758-81f5207f8ac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4433088493b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-4fa628c3f907>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, batch_ix)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mb_x_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mb_x_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mb_x_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4fa628c3f907>\u001b[0m in \u001b[0;36m_get_one\u001b[0;34m(self, ix)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbody_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BodyPartExamined\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mimg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PhotometricInterpretation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4fa628c3f907>\u001b[0m in \u001b[0;36mmake_img\u001b[0;34m(self, img_path, img_type)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_from_dicom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_from_dicom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4fa628c3f907>\u001b[0m in \u001b[0;36mimg_from_dicom\u001b[0;34m(self, img_path, img_type)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         img = tf.image.resize(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1640\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resize method is not implemented: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m   return _resize_images_common(\n\u001b[0m\u001b[1;32m   1643\u001b[0m       \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m       \u001b[0mresize_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0mis_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\'images\\' must have either 3 or 4 dimensions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 instructions)\n\u001b[0;32m--> 538\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name, dim)\u001b[0m\n\u001b[1;32m    363\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must specify an axis argument to tf.expand_dims()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexpand_dims_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   2267\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2270\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]"
     ]
    }
   ],
   "source": [
    "a = gen.__getitem__(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d80cb425-a901-4bc9-8e80-c9a3fecafd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': array([[[[  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          ...,\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3]],\n",
       " \n",
       "         [[  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          ...,\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3]],\n",
       " \n",
       "         [[  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          ...,\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3],\n",
       "          [  3,   3,   3]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[137, 137, 137],\n",
       "          [145, 145, 145],\n",
       "          [151, 151, 151],\n",
       "          ...,\n",
       "          [ 27,  27,  27],\n",
       "          [ 20,  20,  20],\n",
       "          [ 13,  13,  13]],\n",
       " \n",
       "         [[139, 139, 139],\n",
       "          [146, 146, 146],\n",
       "          [151, 151, 151],\n",
       "          ...,\n",
       "          [ 29,  29,  29],\n",
       "          [ 22,  22,  22],\n",
       "          [ 15,  15,  15]],\n",
       " \n",
       "         [[ 98,  98,  98],\n",
       "          [105, 105, 105],\n",
       "          [106, 106, 106],\n",
       "          ...,\n",
       "          [ 21,  21,  21],\n",
       "          [ 15,  15,  15],\n",
       "          [  8,   8,   8]]]], dtype=uint8),\n",
       " 'data': array([[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "       dtype=uint8)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe0ff2-d0c2-4bc3-946d-d215c0330673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
